<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用 antigen 管理 Zsh 配置]]></title>
    <url>%2Fzsh-config%2F</url>
    <content type="text"><![CDATA[介绍 Zsh 是一个 Linux 下强大的 shell, 由于大多数 Linux 产品安装，以及默认使用 bash shell, 但是丝毫不影响极客们对 zsh 的热衷, 几乎每一款 Linux 产品都包含有 zsh，通常可以用 apt-get、urpmi 或 yum 等包管理器进行安装 Zsh 具有以下主要特点： 开箱即用、可编程的命令行补全功能可以帮助用户输入各种参数以及选项 在用户启动的所有 shell 中共享命令历史 通过扩展的文件通配符，可以不利用外部命令达到 find 命令一般展开文件名 改进的变量与数组处理 在缓冲区中编辑多行命令 多种兼容模式，例如使用 / bin/sh 运行时可以伪装成 Bourne shell 可以定制呈现形式的提示符；包括在屏幕右端显示信息，并在键入长命令时自动隐藏 可加载的模块，提供其他各种支持：完整的 TCP 与 Unix 域套接字控制，FTP 客户端与扩充过的数学函数 完全可定制化 虽然说 Zsh 是开箱即用，但是为了更好用，还是需要一些定制化的配置。之前一直使用 oh-my-zsh, oh-my-zsh 把主题、插件等都是一起管理的，但是很多其他的主题和插件，且都是由不同的作者开发的，这样的话，管理起来就比较麻烦。antigen 就是针对此问题，应运而生。 安装 12curl -L git.io/antigen &gt; ~/antigen.zsh# or use git.io/antigen-nightly for the latest version 配置 在 ~/.zshrc 中添加下面的内容 1234567891011121314151617181920212223242526272829source ~/antigen.zsh# Load the oh-my-zsh's library.antigen use oh-my-zsh# Bundles from the default repo (robbyrussell's oh-my-zsh).antigen bundle brewantigen bundle command-not-foundantigen bundle dockerantigen bundle docker-composeantigen bundle gemantigen bundle gitantigen bundle golangantigen bundle ngantigen bundle osxantigen bundle pip# Syntax highlighting bundle.antigen bundle zsh-users/zsh-syntax-highlightingantigen bundle zsh-users/zsh-completionsantigen bundle zsh-users/zsh-autosuggestionsantigen bundle zsh-users/zsh-apple-touchbar# Load the theme.# antigen theme robbyrussellantigen theme https://github.com/denysdovhan/spaceship-prompt spaceship# Tell Antigen that you're done.antigen apply 总结 antigen 完全支持 oh-my-zsh, 第三方的插件或者主题通过 antigen bundle 的方式加载，非常方便。 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>zsh</tag>
        <tag>antigen</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[traefik 配置 docker 容器支持 HTTPS]]></title>
    <url>%2Ftraefik-docker-tls-config%2F</url>
    <content type="text"><![CDATA[介绍 traefik 是一款开源的反向代理与负载均衡工具。它最大的优点是能够与常见的微服务系统直接整合，可以实现自动化动态配置。目前支持 Docker, Swarm, Mesos/Marathon, Mesos, Kubernetes, Consul, Etcd, Zookeeper, BoltDB, Rest API 等等后端模型。 为什么选择 traefik？ Golang 编写，单文件部署，与系统无关，同时也提供小尺寸 Docker 镜像。 支持 Docker/Etcd 后端，天然连接我们的微服务集群。 内置 Web UI，管理相对方便。 自动配置 ACME(Let’s Encrypt) 证书功能。 性能尚可，我们也没有到压榨 LB 性能的阶段，易用性更重要。 Restful API 支持。 支持后端健康状态检查，根据状态自动配置。 支持动态加载配置文件和 graceful 重启。 支持 WebSocket 和 HTTP/2。 借用官网的图，一图以蔽之 需求 使用场景作为一个基于 Angular 的单页 App，与后端 Server通过 RESTful 接口通信，前后端都需要提供 https 支持。使用场景很简单，暂时也没有负载均衡。 准备 根据 traefik 的官方文档中关于 ACME 的说明, Cloudflare 是支持宽域名自动发证书的。 把域名的 DNS 改成 Cloudflare 的 需要的是账户的邮箱地址和 Globel API key 配置 traefik 的配置文件。可以挂载到 docker 容器上 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# debug = truelogLevel = "ERROR" #DEBUG, INFO, WARN, ERROR, FATAL, PANICInsecureSkipVerify = true defaultEntryPoints = ["https", "http"]# WEB interface of Traefik - it will show web page with overview of frontend and backend configurations [web]address = ":8080" [web.auth.basic] usersFile = "/shared/.htpasswd"# Force HTTPS[entryPoints] [entryPoints.http] address = ":80" [entryPoints.http.redirect] entryPoint = "https" [entryPoints.https] address = ":443" [entryPoints.https.tls] [entryPoints.ws] [entryPoints.wss][file] watch = true filename = "/etc/traefik/rules.toml"# Let's encrypt configuration[acme]email = "yong.gu@qlink.mobi" #any email id will workstorage="/etc/traefik/acme/acme.json"entryPoint = "https"acmeLogging=true onDemand = false #create certificate when container is created[acme.dnsChallenge] provider = "cloudflare" delayBeforeCheck = 0[[acme.domains]] main = "example.com"[[acme.domains]] main = "*.example.com" # Connection to docker host system (docker.sock)[docker]endpoint = "unix:///var/run/docker.sock"domain = "example.com"watch = true# This will hide all docker containers that don't have explicitly # set label to "enable"exposedbydefault = false 注：需要发证书的域名在 acme.domains 中配置，这里以 example.com 为例。 docker-compose.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091version: "3.5"services: qlc_wallet_server: image: qlcwallet-server:latest container_name: qlc_wallet_server ports: - "127.0.0.1:8888:8888" networks: - qlcwallet - traefik environment: - DB_PASS=/run/secrets/db_root_password volumes: - type: bind source: ./wallet-server/.env target: /app/config/.env - type: bind source: ./wallet-server/logs target: /var/log/wallet-server secrets: - db_root_password restart: always labels: - "traefik.enable=true" - "traefik.backend=qlc_wallet_server" - "traefik.api.port=8888" - "traefik.api.frontend.rule=Host:api.example.com" - "traefik.docker.network=traefik" qlc_wallet: image: qlcwallet:latest container_name: qlcwallet ports: - "127.0.0.1:4200:80" networks: - qlcwallet - traefik depends_on: - qlc_wallet_server restart: always labels: - "traefik.enable=true" - "traefik.backend=qlc_wallet" - "traefik.port=80" - "traefik.frontend.rule=Host:wallet.example.com" - "traefik.docker.network=traefik" traefik: hostname: traefik image: traefik:latest container_name: traefik restart: always domainname: example.com networks: - qlcwallet - traefik ports: - "80:80" - "443:443" - "8080:8080" environment: - CLOUDFLARE_EMAIL=/run/secrets/traefik_user - CLOUDFLARE_API_KEY=/run/secrets/traefik_api labels: - "traefik.enable=true" - "traefik.backend=traefik" - "traefik.frontend.rule=Host:traefik.example.com" - "traefik.port=8080" - "traefik.docker.network=traefik" volumes: - /var/run/docker.sock:/var/run/docker.sock:ro - ./traefik:/etc/traefik - ./shared:/shared secrets: - traefik_api - traefik_usernetworks: qlcwallet: name: qlcwallet traefik: name: traefiksecrets: db_root_password: file: ./secrets/db_password.txt traefik_api: file: ./secrets/api.txt traefik_user: file: ./secrets/user.txt 这部分包含三部分 qlc_wallet_server RESTful 服务器 qlc_wallet Angular 应用 traefik traefik 本身自带一个简单的 Web 后台，绑定在 8080 端口，可以选择性开启。 这里以 labels 的形式配置，生产环境建议通过 toml 文件的方式配置，这样修改配置不要重启容器。traefik 默认是不会把容器对外发布的，需要手动设置。traefik.port 需要设置成容器内部端口，而不是绑定的外部端口。 总结 总的来说，traefik 配置简单，可以非常快速的搭建测试环境，很方便地支持宽域名证书。另外官方说是支持单容器多端口绑定到不同的 url 上的，但是我一直没试成功。]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>traefik</tag>
        <tag>docker</tag>
        <tag>ACME</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在一台机器上部署多个 GitHub deploy key]]></title>
    <url>%2Fsetup-multiple-github-deploy-keys-in-one-machine%2F</url>
    <content type="text"><![CDATA[需求 在 Github 有几个私有仓库需要做 CI/DI，由于是私有项目，不能用免费的 travis 处理，所以临时在一台服务器上部署了几个脚本，简单处理一下。GitHub 限制了每个项目都必须用不同的 deploy key，我又不想把我自己的私有 key 部署到服务器上。 目标 在一台机器上通过 deploy 拉取 GitHub 私有仓库的代码，编译后做自动部署。 准备 在做 CI/DI 的机器上分别生成不同的 deploy key，并添加到 GitHub repo 里。具体过程这里就不赘述了，官方 帮助文档 写得特别清楚。 配置 更改 git clone 的地址 一般地址的格式为为 git@github.com:$user/$repo.git。我们以三个 repo 为例，假定三个 repo 的名字分别为 repo1,repo2,repo3. 变化后的地址为： git@github.com:$user1/$repo1.git =&gt; ssh://git@$repo1.github.com/$user1/$repo1.git git@github.com:$user1/$repo2.git =&gt; ssh://git@$repo2.github.com/$user1/$repo2.git git@github.com:$user2/$repo3.git =&gt; ssh://git@$repo3.github.com/$user2/$repo3.git 然后在 ~/.ssh/config 中添加下面的配置 1234567891011121314Host repo1.github.comUser gitHostName github.comIdentityFile ~/.ssh/repo1_rsaHost repo2.github.comUser gitHostName github.comIdentityFile ~/.ssh/repo2_rsaHost repo3.github.comUser gitHostName github.comIdentityFile ~/.ssh/repo3_rsa 拉取代码 以 git clone ssh://git@$repo1.github.com/$user1/$repo1.git 的方式拉取代码即可。如果是在修改配置前已经拉取下来的代码，可以修改 repo 的 url 为上面修改后的形式也是一样的。 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Visual Studio Code 调试 Angular 工程]]></title>
    <url>%2Fhowto-debug-angular-with-vscode%2F</url>
    <content type="text"><![CDATA[准备工作 VSCode 安装 Debugger for Chrome 配置 在 Debug 试图增加下面的配置 1234567891011121314151617&#123; // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 "version": "0.2.0", "configurations": [&#123; "name": "Launch localhost with sourcemaps", "type": "chrome", "request": "launch", "url": "http://localhost:4200", "sourceMaps": true, "webRoot": "$&#123;workspaceRoot&#125;", "trace": true, "userDataDir": "$&#123;workspaceRoot&#125;/.vscode/chrome", // "runtimeExecutable": "/opt/google/chrome/google-chrome" &#125;]&#125; 需要注意的是 sourceMaps 一定要设成 true, 如果找不到 chrome 的安装路径，可以手动通过 runtimeExecutable 设置，比如我 Manjarro Linux 下的路径为 /opt/google/chrome/google-chrome 启动 一切配置好之后，在 Angular 工程目录通过 ng serve 启动项目，然后就可以打断点，在 Debug 试图通过 Launch localhost with sourcemaps 这个配置开始调试了。 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>VSCode</tag>
        <tag>Angular</tag>
        <tag>Chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Manjaro 安装及配置]]></title>
    <url>%2Fmanjaro-config%2F</url>
    <content type="text"><![CDATA[Manjaro 是一款基于 Arch Linux、对用户友好、全球排名第 1 的 Linux 发行版。（排名数据源于 DistroWatch） 在 Linux 圈，Arch 的确是一个异常强大的发行版。它有 3 个无与伦比的优势： 滚动更新可以使软件保持最新； AUR 软件仓库有着世界上最齐全的 Linux 软件 丰富的 wiki 和活跃的社区让所有问题都可以快速得到满意的答案 为了解决 ArchLinux 的复杂安装，Manjaro 应运而生！ 准备 下载镜像 可以从 官方 下载镜像，官方支持 Xfore, KDE, GNOME 三种桌面环境，社区版有更多桌面环境支持。根据个人喜好选择，我对 GNOME 版本比较熟悉，所以下载了 GNOME 版。也可以从 清华大学开源镜像 下载。 注： 清华的镜像比官方镜像稍微旧一些。 制作 U 盘启动盘 Windows Manjaro 官方手册推荐用 Rufus 制作启动盘，可惜一直没成功，最后使用 USBwriter 一步到位。 Linux sudo dd bs=4M if=/path/to/manjaro.iso of=/dev/sd[drive letter] status=progress [drive letter] 为 U 盘盘符。 关闭安全启动 小米笔记本 Pro 15.6″ 需要关闭安全启动才能启动。首先插入 U 盘，然后按开机键，并在开机过程中按 F2，会进入 UEFI 设置： 安全 -&gt; 设置密码 安全 -&gt; 关闭 Secure Boot 点击设置密码，但是把 &quot;新密码&quot; 一栏留空，可以实现重置密码 安装 因为小米这台笔记本一直处于吃灰状态，所以安装非常简单，基本上就是无脑下一步就可以了，直接抹掉所有数据。如果是和 Windows 双系统的话，所以需要在不破坏已有引导文件的情况下来安装，因此选择手动分区。 在具体分区时需要将启动盘挂载到 win10 建立的 esp 分区上，挂载点设置为 /boot/efi 标记选择 boot 和 esp 其他的分区和挂载根据自己需要划分。 更新源 执行下面的命令从官方的源列表中对中国源进行测速和设置 1sudo pacman-mirrors -gb testing -c China 增加 Arch Linux CN 源 在 /etc/pacman.conf 文件末尾添加两行 12[archlinuxcn]Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch 注：需要安装 archlinuxcn-keyring 包以导入 GPG key，否则的话 key 验证失败会无法安装的 更新系统 sudo pacman -Syu 常用软件安装 GNU toolchain 1sudo pacman -S base-devel yay 在之前我们管理软件包都是使用官方为我们提供的 pacman，软件包的来源都是官方。yaourt 实际上也是一个软件包，我们可以把它看成是对 pacman 的包装，它兼容 pacman 的所有操作，最大的不同是我们可以用它方便地安装与管理 AUR 中的包，下面的许多软件包都是在 AUR 库中的，也都是使用 AUR 来安装的。具体使用，可以参考 这里 1sudo pacman -Sy yay fakeroot 注： yay 默认使用的是 pacman 的配置，所以默认控制台是没有颜色的，需要在 /etc/pacman.conf 中的 Color 选项开启， via #123 字体 1yay noto-fonts noto-fonts-cjk noto-fonts-emoji wqy-microhei wqy-microhei-lite 文泉驿 wqy-microhei - 文泉驿微米黑，无衬线形式字体。 wqy-microhei-lite - 文泉驿微米黑 light 版（笔画更细） 输入法 目前主流的输入法框架就是 fcitx 和 iBus 两种， iBus bug 稍微多一点。输入法基本上就是 Sogou 和 Rime。 Rime 要配置，我还没找到主题配置的地方，Sogou 基本上就是开箱即用。 使用了一段时间后，还是把输入法改成了 Rime。 1yay -S ibus ibus-qt ibus-rime 在 ~/.xprofile 添加下面的内容 1234export GTK_IM_MODULE=ibusexport XMODIFIERS=@im=ibusexport QT_IM_MODULE=ibusibus-daemon -d -x 注：Gnome 自带 iBus 的管理界面， 所以你只需要安装的输入法引擎, 并在 Region &amp; Language 中的 “Input Sources” 添加进去。在你添加至少两个输入源后，GNOME 会在托盘中显示输入选择图标。 zsh zsh 是默认 shell bash 的替代品之一，它的特点是插件多配置方便，兼容 bash 脚本并且支持更强大的高亮与补全。 123yaourt zsh powerline-fonts powerline# 安装 oh-my-zshsh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)" 注： 也可以使用 fish，但是和 bash 是不兼容的，看个人喜好。 Synapse Synapse 是类似 macOS Alfred 的应用启动器。 1yaourt synapse 剪贴板 CopyQ 是一个剪贴板管理工具，类似 Ditto。 1yaourt copyq 微信 目前官方没有出过 Linux 版本，Linux 平台只有 Web 版。用三个选择，wine 安装 Windows 版本，Deepin 已经做过一些修改，但是这个版本的字体显示不是很好。还有两个分别是 electronic-wechat 和 wewechat，后两者都是基于 Web 版封装的，wewechat 更彻底一点，三个都可以通过 AUR 安装。使用体验上来说都没办法和 Windows 、macOS 平台相比，聊胜于无吧。 1yay -S electronic-wechat wewechat deepin.com.wechat 其他 配置 SSH 配置 Git 配置 gpg 安装 IDE (Jetbrains ...) etc ... 1yaourt clion gitahead typora ieaseMusic code ... 备份 简单配置了一下 Timeshift，整体体验远不如 macOS TimeMachine，不过毕竟价格差异在这里，还要什么自行车。 小结 总的来说， Manjaro 安装方便，有 AUR 加持，安装包非常方便，作为主力开发环境使用了一段时间总体觉得还可以。搭建开发环境来说，基本与 macOS 相当，有些环境需要 sudo，这点不如 Brew，不过稍微配置还说有版本实现的。 参考链接 Writing_to_a_USB_Stick_in_Linux Xiaomi Mi Notebook Air 13.3 Fonts ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Manjaro</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clion WSL 工具链配置]]></title>
    <url>%2Fclion-wsl%2F</url>
    <content type="text"><![CDATA[安装 WSL 以管理员权限运行 owershell 并执行下面的指令 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 在 Microsoft Store 中安装 Ubuntu。 目前 Windows 支持多种 Linux 发行版，但 Ubuntu 作为使用门槛最低的版本，这里以此为例。 与 Windows 共享配置 通过软链接 Windows 的用户到 WSL，这样就可以共享一些软件的配置信息，比如 git, ssh 等。 123456# 删除原有用户目录sudo rm -rf /home/goreng# 链接 Windows 用户目录到 WSL 中sudo ln -sf /mnt/c/User/&lt;windows user name&gt; /home/goreng# 更改访问租信息sudo chown -R goreng:goreng /home/goreng goreng 为 WSL 用户名 修改 Ubuntu 源 修改 Ubuntu 默认源为镜像配置并关闭 deb-src 12sudo sed -i -e 's%http://archive.ubuntu.com/ubuntu%mirror://mirrors.ubuntu.com/mirrors.txt%' -e 's/^deb-src/#deb-src/' /etc/apt/sources.listsudo apt-get upate &amp;&amp; sudo apt-get upgrade 安装 Clion 依赖 Jetbrains 官方给出一键安装的脚本，基本上就是安装基本的开发包，并配置了 SSH Server 用于远程调试 1wget https://raw.githubusercontent.com/JetBrains/clion-wsl/master/ubuntu_setup_env.sh &amp;&amp; bash ubuntu_setup_env.sh 注：此处脚本执行完会打印 SSH 连接信息，后面会用到 安装常用开发组件 1sudo apt-get install git zsh python-dev python-pip fonts-powerline gnupg2 qtbase5-dev 配置 zsh 安装 oh-my-zsh 1sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; 安装 powerline-shell 安装 pip install powerline-shell 添加到 ~/.zshrc 中 12345678910111213141516function powerline_precmd() &#123; PS1="$(powerline-shell --shell zsh $?)"&#125;function install_powerline_precmd() &#123;for s in "$&#123;precmd_functions[@]&#125;"; do if [ "$s" = "powerline_precmd" ]; then return fidoneprecmd_functions+=(powerline_precmd)&#125;if [ "$TERM" != "linux" ]; then install_powerline_precmdfi 编译 boost 12345wget --quiet -O boost_1_67_0.tar.gz https://dl.bintray.com/boostorg/release/1.67.0/source/boost_1_67_0.tar.gztar xf boost_1_67_0.tar.gzcd boost_1_67_0./bootstrap.sh./b2 link=static install 编译 cmake 123456wget --quiet -O cmake-3.11.4.tar.gz https://cmake.org/files/v3.11/cmake-3.11.4.tar.gztar xf cmake-3.11.4.tar.gzcd cmake-3.11.4./bootstrapmakesudo make install 注：由于 Ubuntu 源中的 cmake 版本比较低，对 boost 支持不好，所以手动编译官方最新的 release 版 配置 Clion 由于 WSL 是文件名大小写敏感，所以需要修改 Clion 的配置。在 Help -&gt; “Edit Custom Properties…” 中添加 idea.case.sensitive.fs=true 然后重启并重建索引。 (File -&gt; “Invalidate Caches and Restart”) 小结 对于 Windows 平台来说，有了 WSL 之后多了一个选择，但是 WSL 的稳定性还是有挺大问题，比如在我做了这一大堆配置之后，WSL 起不起来了。 Clion 对 WSL 的支持也是处于比较初级的阶段，gdb 调试的时候，对 C++ STL value 的显示也不友好。via GDB pretty printers don't work for std::string and std::list with GCC-5 and higher 综上所述，在 Windows 平台还是用宇宙最强 IDE Visual Studio 吧。 参考链接 CLion and Linux toolchain on Windows are now friends! Getting Started on Unix Variants Installing CMake ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Clion</tag>
        <tag>WSL</tag>
        <tag>Windows Subsystem for Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose 编排 DevOps 工具]]></title>
    <url>%2Fdocker-devops-kits%2F</url>
    <content type="text"><![CDATA[介绍 在 Docker nginx 反向代理设置 介绍了通过 nginx 反向代理关联容器。此为真实的使用场景。通过 Gitea 作为代码管理工具；Kanboard 作为任务管理；Jenkins 作为 CI 工具。这样的组合比较适合小型团队使用，相比起 GitLab 这种巨无霸来说，部署简单，使用简单。 准备 安装 Docker 1234567891011121314151617$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh&lt;output truncated&gt;If you would like to use Docker as a non-root user, you should now consideradding your user to the "docker" group with something like:sudo usermod -aG docker your-userRemember to log out and back in for this to take effect!WARNING: Adding a user to the "docker" group grants the ability to run containers which can be used to obtain root privileges on the docker host. Refer to https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface for more information. 安装 Docker Compose 123$ sudo curl -L https://github.com/docker/compose/releases/download/1.19.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose$ docker-compose --version 注：Docker 以及 Docker Compose 的安装，官方文档讲得非常清晰，在此不再赘述。 docker-compose.yml 文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114version: "3.5"services: mysql: image: mysql:latest container_name: mysql ports: - "3306:3306" networks: - devops environment: - MYSQL_ROOT_PASSWORD=/run/secrets/db_root_password volumes: - type: bind source: ./mysql/conf.d target: /etc/mysql/conf.d - type: bind source: ./mysql/data target: /var/lib/mysql # - ./mysql/conf.d:/etc/mysql/conf.d # - ./mysql/data:/var/lib/mysql secrets: - db_root_password restart: always gitea: image: gitea/gitea:latest container_name: gitea ports: - "10080:3000" - "10022:22" networks: - devops environment: - VIRTUAL_HOST=git.vking.io - VIRTUAL_PORT=3000 - GITEA_CUSTOM=/etc/gitea depends_on: - mysql volumes: - type: bind source: ./gitea target: /data - type: bind source: ./gitea/custom target: /etc/gitea # - ./gitea:/data # - ./gitea/custom:/etc/gitea restart: always task: image: kanboard/kanboard:latest container_name: kanboard ports: - "8888:80" networks: - devops environment: - VIRTUAL_HOST=task.vking.io - VIRTUAL_PORT=80 volumes: - type: bind source: ./kanboard/data target: /var/www/app/data - type: bind source: ./kanboard/plugins target: /var/www/app/plugins # - ./kanboard/data:/var/www/app/data # - ./kanboard/plugins:/var/www/app/plugins restart: always jenkins: image: jenkins/jenkins:lts container_name: jenkins ports: - "8081:8080" - "50000:5000" networks: - devops environment: - VIRTUAL_HOST=jenkins.vking.io - VIRTUAL_PORT=8080 volumes: - type: bind source: ./jenkins/data target: /var/jenkins_home # - ./jenkins/data:/var/jenkins_home restart: always nginx: image: jwilder/nginx-proxy:alpine container_name: nginx ports: - "80:80" depends_on: - gitea - task - jenkins networks: - devops volumes: - type: bind source: /var/run/docker.sock target: /tmp/docker.sock # - /var/run/docker.sock:/tmp/docker.sock restart: alwayssecrets: db_root_password: file: ./mysql/my_secret.txtnetworks: devops: name: devops-network 注: 通过 volumes bind 方式挂载的外部文件/目录，如果不存在的话，不会自动创建。 使用 MySQL 的管理员密码，通过 mysql/my_my_secret.txt 设置，构建容器的时候会自动加载并设置。 不同 services 管理的域名，通过环境变量设置 VIRTUAL_HOST=域名；VIRTUAL_PORT=端口 创建镜像并执行 docker-compose up -d 删除容器及 volumn 数据 docker-compose down -v 后记 因为通过反向代理隐藏了暴露端口的细节，如果没有外部注册的域名的话，还需要通过 Dnsmasq 进行内部域名解析。 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>nginx</tag>
        <tag>Docker Compose</tag>
        <tag>Git</tag>
        <tag>Gitea</tag>
        <tag>DevOps</tag>
        <tag>Jenkins</tag>
        <tag>Kanboard</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA 通过数据库生成 Nutz 实体类]]></title>
    <url>%2Fidea-generate-nutz-entity-from-database%2F</url>
    <content type="text"><![CDATA[缘起 Nutz 是一套开源的 Web Framework(Mvc/Ioc/Aop/Dao/Json)，其中 Dao 模块是针对 JDBC 的薄封装，事务模板，无缓存。在数据库已经设计好之后，手动写对应的 Entity 的话，是个无比痛苦且无意义的事情。下面就通过 IDEA 自带的 DataGrip 基础上根据数据库信息一键生成 Entity 插件 在 Scratches 视图下的 Extensions/schema 新建一个文件，命名任意，比如 Generate nutz POJOs.groovy 把下面的代码复制到刚才创建的文件中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import com.intellij.database.model.DasTableimport com.intellij.database.model.ObjectKindimport com.intellij.database.util.Caseimport com.intellij.database.util.DasUtil/** Available context bindings:* SELECTION Iterable&lt;DasObject&gt;* PROJECT project* FILES files helper*//* 包名，也可以直接修改生成的 Java 文件 */packageName = "com.sample;"typeMapping = [ (~/(?i)int/) : "long", (~/(?i)float|double|decimal|real/): "double", (~/(?i)datetime|timestamp/) : "java.sql.Timestamp", (~/(?i)date/) : "java.sql.Date", (~/(?i)time/) : "java.sql.Time", (~/(?i)/) : "String"]FILES.chooseDirectoryAndSave("Choose directory", "Choose where to store generated files") &#123; dir -&gt; SELECTION.filter &#123; it instanceof DasTable &amp;&amp; it.getKind() == ObjectKind.TABLE &#125;.each &#123; generate(it, dir) &#125;&#125;def generate(table, dir) &#123; def className = javaName(table.getName(), true) def fields = calcFields(table) new File(dir, className + ".java").withPrintWriter &#123; out -&gt; generate(out, table, className, fields) &#125;&#125;def generate(out, table, className, fields) &#123; out.println "package $packageName" /* 可在此添加需要导入的包名，也可通过 IDE 批量修改生成的 Java 文件 */ out.println "" out.println "" out.println "@Table(\"$&#123;table.getName()&#125;\")" out.println "public class $className &#123;" out.println "" fields.each() &#123; if (it.annos != "") out.println " $&#123;it.annos&#125;" out.println " @Column(\"$&#123;it.col&#125;\")" out.println " private $&#123;it.type&#125; $&#123;it.name&#125;;" &#125; out.println "" fields.each() &#123; out.println "" out.println " public $&#123;it.type&#125; get$&#123;it.name.capitalize()&#125;() &#123;" out.println " return $&#123;it.name&#125;;" out.println " &#125;" out.println "" out.println " public void set$&#123;it.name.capitalize()&#125;($&#123;it.type&#125; $&#123;it.name&#125;) &#123;" out.println " this.$&#123;it.name&#125; = $&#123;it.name&#125;;" out.println " &#125;" out.println "" &#125; out.println "&#125;"&#125;def calcFields(table) &#123; DasUtil.getColumns(table).reduce([]) &#123; fields, col -&gt; def spec = Case.LOWER.apply(col.getDataType().getSpecification()) def typeStr = typeMapping.find &#123; p, t -&gt; p.matcher(spec).find() &#125;.value fields += [[ name : javaName(col.getName(), false), type : typeStr, col : col.getName(), annos: ""]] &#125;&#125;def javaName(str, capitalize) &#123; def s = com.intellij.psi.codeStyle.NameUtil.splitNameIntoWords(str) .collect &#123; Case.LOWER.apply(it).capitalize() &#125; .join("") .replaceAll(/[^\p&#123;javaJavaIdentifierPart&#125;[_]]/, "_") capitalize || s.length() == 1 ? s : Case.LOWER.apply(s[0]) + s[1..-1]&#125; 生成 Entity 注：首先需要创建数据库连接，选中要生成的 Entity 的表，右键选择 Generate nutz POJOs.groovy 即可。 后记 代码在 IDEA 自带的 Generate POJOs.groovy 基础上修改而成，如果需要其他规范的实体类，比如 JPA 只要稍作修改即可。 ---EOF---]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>Groovy</tag>
        <tag>Nutz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scoop 安装使用]]></title>
    <url>%2Fscoop-config%2F</url>
    <content type="text"><![CDATA[介绍 Scoop 是 Windows 上的命令行安装程序 特点如下： 大多数程序安装不需要管理员权限 自动设置环境变量 命令行操作，类似 macOS 下的 HomeBrew 常见开发环境都可以轻松搞定 安装 以管理员账号启动 Powershell，输入以下命令 123456psversiontable.psversion.major # should be &gt;= 3set-executionpolicy remotesigned -scope currentuser# 自定义安装路径(可选)[environment]::setEnvironmentVariable('SCOOP','D:\Scoop','User')$env:SCOOP='D:\Scoop'iex (new-object net.webclient).downloadstring('https://get.scoop.sh') 如果没报错，就表示安装成功 添加官网扩展支持 12scoop bucket add extrasscoop bucket add versions 使用 支持命令 123456789101112131415161718192021222324252627Usage: scoop &lt;command&gt; [&lt;args&gt;]Some useful commands are:alias Manage scoop aliasesbucket Manage Scoop bucketscache Show or clear the download cachecheckup Check for potential problemscleanup Cleanup apps by removing old versionsconfig Get or set configuration valuescreate Create a custom app manifestdepends List dependencies for an appexport Exports (an importable) list of installed appshelp Show help for a commandhome Opens the app homepageinstall Install appslist List installed appsreset Reset an app to resolve conflictssearch Search available appsstatus Show status and check for new app versionsuninstall Uninstall an appupdate Update apps, or Scoop itselfvirustotal Look for app's hash on virustotal.comwhich Locate a shim/executable (similar to 'which' on Linux)Type 'scoop help &lt;command&gt;' to get help for a specific command. 基本命令 12345678910# 查找软件scoop search sublime-text#全局安装sudo scoop install oraclejdk python -g #一般安装scoop install sublime-text #更新scoop update sublime-text #卸载scoop uninstall sublime-text 导出安装软件列表 scoop.cmd export &gt; app_list.txt 更新所有安装软件 scoop update * &amp;&amp; scoop cleanup * Python 版本切换 12345678910scoop install python27 pythonpython --version # -&gt; Python 3.6.2# switch to python 2.7.xscoop reset python27python --version # -&gt; Python 2.7.13# switch back (to 3.x)scoop reset pythonpython --version # -&gt; Python 3.6.2 注：Ruby 版本切换类似，都是通过 scoop reset 切换 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Scoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eclipse 配置及插件]]></title>
    <url>%2Feclipse-plugin%2F</url>
    <content type="text"><![CDATA[虽然我现在基本上转到 Jetbrains IDEA 了，办公室有些小朋友还是坚守 eclipse，简单整理下常用插件和配置。 插件 名称 备注 安装 Buildship Eclipse Gradle 插件 Darkest Dark Theme w/DevStyle 黑色主题 Checkstyle 代码风格检查 Enhanced Class Decompiler 反编译插件，集成 JD, Jad, FernFlower, CFR, Procyon seamlessly with Eclips Java Source Attacher 下载 jar 包代码包并关联 Kotlin Kotlin 语言支持 SonarLint for Eclipse 代码静态检查 SpotBugs 代码静态检查 TestNG 测试框架 注： 如果安装了 Marketplace Client 可直接导入配置而无需手动添加。具体步骤为：File-&gt;Import/Install/Install Software Items from File，然后选中配置文件即可。 配置 智能提示 Java/Content Assint/Auto Activation/Auto activation triggers for java 为 .abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ(, @ 字体设置 General/Appearance/Colors and Fonts 设置字体 文件编码 文件编码默认为 GBK，可通过 General/Workspace/Text file encoding/Other 选中 UTF-8 修改 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>IDE</tag>
        <tag>Plugin</tag>
        <tag>eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA 插件]]></title>
    <url>%2FIntelliJ-IDEA-plugins%2F</url>
    <content type="text"><![CDATA[语言相关 Kotlin Jetbrains 官方 Kotlin 插件 Go Jetbrains 官方 Golang 插件 工具类 Key promoter X 快捷键辅助工具 .ignore Git ignore 高亮等 CheckStyle-IDEA 代码规范检查 FindBugs-IDEA 潜在 Bug 检查 Statistic 代码统计 代码生成 String Manipulation 驼峰式命名和下划线命名交替变化 Maven Helper Maven 辅助工具 JsonToKotlinClass 转换 Json 字符串 为 Kotlin 类 GsonFormat 把 Json 字符串为 Java 类 OK, Gradle! Gradle 辅助工具 Gradle Dependencies Formatter 转换 Maven 依赖为 Gradle 语法等 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Jetbrains</tag>
        <tag>IDEA</tag>
        <tag>IDE</tag>
        <tag>Plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Java 应用镜像]]></title>
    <url>%2FDocker-java-app-container%2F</url>
    <content type="text"><![CDATA[最近一个项目中由于使用了不同的版本的 JDK 导致兼容问题，故把不同的应用通过 Docker 分别包装了一下，为了减少镜像大小，选用基于 [AlpineLinux] 的镜像作为基础镜像。 主要完成了下面几件事情： 设置时区为北京时间 添加 docker-entrypoint.sh 做基础的环境变量检查（可选） 配置 VOLUME，方便通过挂载不同的目录复用 启动 Java 程序 构建镜像 新建文件夹，名字任务，包含下面两个文件 Dockerfile 123456789101112FROM anapsix/alpine-javaLABEL maintainer "gythialy@outlook.com"COPY docker-entrypoint.sh /usr/local/bin/ENV TZ=Asia/Shanghai \ PATH=/usr/local/bin/:$PATH RUN chmod +x /usr/local/bin/docker-entrypoint.sh \ &amp;&amp; ln -s /usr/local/bin/docker-entrypoint.sh /entrypoint.sh \ &amp;&amp; apk add --no-cache tzdata \ &amp;&amp; rm -rf /var/cache/apk/* ENTRYPOINT ["docker-entrypoint.sh"]VOLUME [ "/opt/app" ]CMD ["sh", "-c", "/opt/app/$&#123;LIB_PATH&#125;"] docker-entrypoint.sh 12345678910#!/bin/bashset -eo pipefailshopt -s nullglobif [ -z "$LIB_PATH" ]; then echo &gt;&amp;2 'You need to specify LIB_PATH' exit 1fiexec "$@" 注： 这不是必须的，这边只是简单检查了下 LIB_PATH 是不是指定了 构建镜像 123456# 构建镜像docker build -t gythialy/java-app . # 推送到私有仓库docker tag gythialy/java-app hub.vking.io/java-app:alpine docker push hub.vking.io/java-app:alpine 构建 Java 应用 Gradle 构建出的 Java 程序目录如下，通过 bin/jx-ws 启动程序。 1234567891011.├── bin│ ├── jx-ws│ ├── jx-ws.bat│ ├── logs│ │ ├── 2018-01│ │ │ └── ws-2018-01-31-1.log│ │ └── ws.log│ └── ws.json└── lib └── jx-ws-1.1.1-all.jar 构建并启动容器 12345678910111213#!/bin/bashset -eapp_name=java-testdocker stop $app_name || true \&amp;&amp; docker rm $app_name || true \&amp;&amp; docker run --name $app_name -d \ --restart always \ -e LIB_PATH=bin/jx-ws \ -v /home/vking/wks/jx-ws/jx-ws-shadow-1.1.1:/opt/app \ hub.vking.io/java-app:alpine ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 Docker 私有镜像]]></title>
    <url>%2FDocker-Private-registry%2F</url>
    <content type="text"><![CDATA[介绍 目前部署私有 Docker Registry 有下面几个选择 Vmware Harbor 官方 Registry Portus nexus 官方 registry 比较简单，没有 UI 界面；Portus 其实也是基于官方 registry ，可以理解为官方增强版，同时提供了部署的示例；Harbor，nexus 等都比较重量级，部署比较麻烦，这里暂时不考虑。由于我们的使用场景非常简单，所有选用官方 registry 镜像如何部署私有服务器。下面简单介绍下如何配置。 官方 Registry 配置，详细配置介绍 12345678910111213141516171819202122232425version: 0.1log: accesslog: disabled: true level: debug formatter: text fields: service: registry environment: stagingstorage: delete: enabled: true cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registryhttp: addr: :5000 headers: X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10sthreshold: 3 启动 1234567891011121314#!/bin/bashset -eregistry_id=registrydocker stop $registry_id || true &amp;&amp; docker rm $registry_id || true\&amp;&amp; docker run --name $registry_id -d\ --restart always \ --network registry-net \ -p 5000:5000 \ -v /srv/docker/registry/config.yml:/etc/docker/registry/config.yml \ -v /srv/docker/registry/data:/var/lib/registry \ registry 配置 UI 由于官方镜像只有后台，提供了一组 RESTful API，UI 需要单独配置，可以选 docker-registry-web，docker-registry-ui，这里就以 docker-registry-ui 为例，操作都大同小异。 1234567891011121314#!/bin/bashset -eapp_id=registry-uidocker stop $app_id || true &amp;&amp; docker rm $app_id || true\&amp;&amp; docker run --name $app_id -d\ --restart always \ --network registry-net \ -p 8088:80 \ -e REGISTRY_URL=http://registry:5000 \ -e DELETE_IMAGES=true \ joxit/docker-registry-ui:static 配置反向代理 如果需要通过 nginx 配置反向代理的话，需要注意添加 client_max_body_size 和 chunked_transfer_encoding 设置，具体参考 Docker nginx 反向代理设置。 123456789101112131415161718192021upstream hub.vking.io &#123; # jenkins server registry:5000;&#125;server&#123; server_name hub.vking.io; # disable any limits to avoid HTTP 413 for large image uploads client_max_body_size 0; # required to avoid HTTP 411: see Issue #1486 (https://github.com/moby/moby/issues/1486) chunked_transfer_encoding on; listen 80; location / &#123; proxy_pass http://hub.vking.io; &#125; access_log /var/log/nginx/access.log vhost;&#125; 参考资料 https://docker_practice.gitee.io/repository/registry.html https://docs.docker.com/registry/ ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Registry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker nginx 反向代理设置]]></title>
    <url>%2FDocker-nginx-reverse-proxy%2F</url>
    <content type="text"><![CDATA[缘起 最近在公司搭建了一个基于 Gogs 的代码管理系统，以及基于 Kanboard 的任务管理系统等几个内部系统。由于部署在同一台机器上，基于不同的端口区分不同的服务。比如： Git 服务 http://10.10.1.110:10080 任务管理系统http://10.10.1.110:8888 其他 为了更好的使用，通过内部域名区分，比如 ： Git 服务 http://gogs.vking.io 任务管理系统 http://task.vking.io 其他 注：vking.io 是内部域名，可通过 dnsmasq 配置。 方案一 现有服务都是通过 Docker 部署，nginx 同样通过 Docker 部署，使用官方提供的镜像即可。 新建 nginx 配置文件， nginx.conf，存放路径为 /srv/docker/nginx/nginx.conf 123456789101112131415161718192021222324252627282930# user nginx;worker_processes auto;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf;&#125;# daemon off; 新建反向代理设置文件 reverse-proxy.conf，存放路径为 /srv/docker/nginx/conf.d/reverse-proxy.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# If we receive X-Forwarded-Proto, pass it through; otherwise, pass along the# scheme used to connect to this servermap $http_x_forwarded_proto $proxy_x_forwarded_proto &#123; default $http_x_forwarded_proto; '' $scheme;&#125;# If we receive X-Forwarded-Port, pass it through; otherwise, pass along the# server port the client connected tomap $http_x_forwarded_port $proxy_x_forwarded_port &#123; default $http_x_forwarded_port; '' $server_port;&#125;# If we receive Upgrade, set Connection to "upgrade"; otherwise, delete any# Connection header that may have been passed to this servermap $http_upgrade $proxy_connection &#123; default upgrade; '' close;&#125;# Apply fix for very long server namesserver_names_hash_bucket_size 128;# Default dhparamssl_dhparam /etc/nginx/dhparam/dhparam.pem;# Set appropriate X-Forwarded-Ssl headermap $scheme $proxy_x_forwarded_ssl &#123; default off; https on;&#125;gzip_types text/plain text/css application/javascript application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;log_format vhost '$host $remote_addr - $remote_user [$time_local] ' '"$request" $status $body_bytes_sent ' '"$http_referer" "$http_user_agent"';access_log off;# HTTP 1.1 supportproxy_http_version 1.1;proxy_buffering off;proxy_set_header Host $http_host;proxy_set_header Upgrade $http_upgrade;proxy_set_header Connection $proxy_connection;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header X-Forwarded-Proto $proxy_x_forwarded_proto;proxy_set_header X-Forwarded-Ssl $proxy_x_forwarded_ssl;proxy_set_header X-Forwarded-Port $proxy_x_forwarded_port;# Mitigate httpoxy attack (see README for details)proxy_set_header Proxy "";server &#123; server_name _; # This is just an invalid value which will never trigger on a real hostname. listen 80; access_log /var/log/nginx/access.log vhost; return 503;&#125;# gogs.vking.ioupstream gogs.vking.io &#123; # gogs server gogs:3000;&#125;server&#123; server_name gogs.vking.io; listen 80; location / &#123; proxy_pass http://gogs.vking.io; &#125; access_log /var/log/nginx/access.log vhost;&#125;# task.vking.ioupstream task.vking.io &#123; # kanboard server kanboard:80;&#125;server&#123; server_name task.vking.io; listen 80; location / &#123; proxy_pass http://task.vking.io; &#125; access_log /var/log/nginx/access.log vhost;&#125; gogs 启动命令 1234567docker container run -d --name gogs \ --restart always \ -p 10022:22 \ -p 10080:3000 \ --network gogs-net \ -v /srv/docker/gogs:/data \ gogs/gogs:latest 注： upstream gogs.vking.io 中的 server 中的 gogs:3000 分别指容器名称和原始expose 的端口。 启动容器 1234567docker container run -d --name nginx \ --restart always \ -p 80:80 \ --network gogs-net \ -v /srv/docker/nginx/nginx.conf:/etc/nginx/nginx.conf \ -v /srv/docker/nginx/conf.d:/etc/nginx/conf.d \ nginx:alpines 注：--network gogs-net 指定三个容器在同一网络，如果用默认的 bridge的话，不需要设置 方案二 因为这些服务都是部署在一台机器上的，可以通过 Docker 的自动服务发现部署，原理见此。 gogs 12345678docker container run -d --name gogs \ --restart always \ -p 10022:22 -p 10080:3000 \ --network gogs-net \ -e VIRTUAL_HOST=gogs.vking.io \ -e VIRTUAL_PORT=3000 \ -v /opt/docker/gogs:/data \ gogs/gogs:latest Kanboard 123456789docker container run -d --name kanboard \ --restart always \ -p 8888:80 \ --network gogs-net \ -e VIRTUAL_HOST=task.vking.io \ -e VIRTUAL_PORT=80 \ -v /srv/docker/kanboard/data:/var/www/app/data \ -v /srv/docker/kanboard/plugins:/var/www/app/plugins \ kanboard/kanboard:latest nginx 123456docker container run -d --name nginx \ --restart always \ -p 80:80 \ --network gogs-net \ -v /var/run/docker.sock:/tmp/docker.sock:ro \ jwilder/nginx-proxy:alpine 注：关键是容器通过 -e VIRTUAL_HOST 指定 url，通过 -e VIRTUAL_PORT=80 指定端口，同样端口也必须是原始镜像 expose 的端口。 延伸 目前服务都是通过 shell 启动，可改成通过 Docker Compose 统一编排任务，把 dnsmasq+nginx+gogs+... 等统一管理。如果是部署在公网上的话，还可以把 SSL 证书到期自动刷新等一起编排。 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>nginx</tag>
        <tag>Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装配置 Supervisor]]></title>
    <url>%2Finstall-and-config-supervisor%2F</url>
    <content type="text"><![CDATA[在线安装 通过 Setuptools安装 easy_install supervisor Ubuntu 安装 sudo apt-get install supervisor 离线安装 从 PyPi 下载 supervisor离线包 下载依赖项 setuptools (latest) from http://pypi.python.org/pypi/setuptools. meld3 (latest) from http://www.plope.com/software/meld3/. 分别通过 python setup.py install 安装 注：根据不同的系统，可能需要 root 权限执行安装 配置 生成默认配置 1234# 创建配置文件目录mkdir -p /etc/supervisor# 生成默认配置sudo sh -c '/usr/local/bin/echo_supervisord_conf &gt; /etc/supervisor/supervisor.conf' 修改配置 123456789[program:jx-ws]command = /bin/bash jx-wsdirectory = /home/$&#123;user.home&#125;/opt/jx-ws-shadow-1.0.0/binautostart = trueautorestart = truestdout_logfile = /var/log/ws/out.logstdout_logfile_maxbytes = 50MBstderr_logfile = /var/log/ws/err.logstderr_logfile_maxbytes = 10MB 说明: 如果启动的程序为 shell，需要在前面增加 /bin/bash directory 设置为可执行程序的上级目录 log目录不会自动创建，需手动创建，但是日志文件会自动生成 Java 中通过 user.dir获取到的目录为 supervisor 的目录，如需获取程序所在 jar 的运行目录需自行处理 启动需要 root 权限，可通过 sudo supervisord -c /etc/supervisor/supervisor.conf 指定配置路径 运行 启动 sudo supervisord -c /etc/supervisor/supervisor.conf 12345678910111213141516171819202122232425262728supervisord -- run a set of applications as daemons.Usage: /usr/bin/supervisord [options]Options:-c/--configuration FILENAME -- configuration file-n/--nodaemon -- run in the foreground (same as 'nodaemon=true' in config file)-h/--help -- print this usage message and exit-v/--version -- print supervisord version number and exit-u/--user USER -- run supervisord as this user (or numeric uid)-m/--umask UMASK -- use this umask for daemon subprocess (default is 022)-d/--directory DIRECTORY -- directory to chdir to when daemonized-l/--logfile FILENAME -- use FILENAME as logfile path-y/--logfile_maxbytes BYTES -- use BYTES to limit the max size of logfile-z/--logfile_backups NUM -- number of backups to keep when max bytes reached-e/--loglevel LEVEL -- use LEVEL as log level (debug,info,warn,error,critical)-j/--pidfile FILENAME -- write a pid file for the daemon process to FILENAME-i/--identifier STR -- identifier used for this instance of supervisord-q/--childlogdir DIRECTORY -- the log directory for child process logs-k/--nocleanup -- prevent the process from performing cleanup (removal of old automatic child log files) at startup.-a/--minfds NUM -- the minimum number of file descriptors for start success-t/--strip_ansi -- strip ansi escape codes from process output--minprocs NUM -- the minimum number of processes available for start success--profile_options OPTIONS -- run supervisord under profiler and output results based on OPTIONS, which is a comma-sep'd list of 'cumulative', 'calls', and/or 'callers', e.g. 'cumulative,callers') 查看状态 sudo supervisorctl status 1234567891011121314151617181920supervisorctl -- control applications run by supervisord from the cmd line.Usage: /usr/bin/supervisorctl [options] [action [arguments]]Options:-c/--configuration FILENAME -- configuration file path (default /etc/supervisord.conf)-h/--help -- print usage message and exit-i/--interactive -- start an interactive shell after executing commands-s/--serverurl URL -- URL on which supervisord server is listening (default "http://localhost:9001").-u/--username USERNAME -- username to use for authentication with server-p/--password PASSWORD -- password to use for authentication with server-r/--history-file -- keep a readline history (if readline is available)action [arguments] -- see belowActions are commands like "tail" or "stop". If -i is specified or no action isspecified on the command line, a "shell" interpreting actions typedinteractively is started. Use the action "help" to find out about availableactions. XML-RPC API Documentation 配置 1234[inet_http_server] ; inet (TCP) server disabled by defaultport=127.0.0.1:9001 ; (ip_address:port specifier, *:port for all iface)username=ops ; (default is no username (open server))password=vipshop ; (default is no password (open server)) 连接 12import xmlrpclibserver = xmlrpclib.Server('http://ops:vipshop@127.0.0.1:9001/RPC2') 查询API 支持的接口 12methods = server.system.listMethods()print methods ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 travis 添加 ssh key]]></title>
    <url>%2Ftravis-add-ssh-key%2F</url>
    <content type="text"><![CDATA[生成 SSH key 生成 1ssh-keygen -t rsa -b 4096 -C "&lt;your_email&gt;" -f github_deploy_key -N '' 注： 这里使用 github_deploy_key 作为存储的名字 这会生成两个文件 公钥 github_deploy_key.pub 私钥 github_deploy_key 拷贝公钥到剪贴板 12# Copies the contents of the id_rsa.pub file to your clipboard$ clip &lt; ~/.ssh/github_deploy_key.pub 如果是做为项目的部署公钥，需要添加到项目中，以 GitHub 为例，添加公钥的时候需要勾上 Allow Write Access 删除 github_deploy_key.pub 1rm github_deploy_key.pub 安装 The Travis Client 首先确保已经安装好 Ruby(1.9.3+)，官方推荐 2.0.0 执行 gem install travis -v 1.8.8 --no-rdoc --no-ri 安装 travis client 检查安装是否正确 travis version 加密 SSH key 加密文件 1travis encrypt-file github_deploy_key 加密后的文件为 github_deploy_key.enc 会输出类似的结果： 1234567891011encrypting github_deploy_key for &lt;username&gt;/&lt;repository&gt;storing result as github_deploy_key.encstoring secure env variables for decryptionopenssl aes-256-cbc -K $encrypted_XXXXXXXXXXXX_key -iv $encrypted_XXXXXXXXXXXX_iv -in github_deploy_key.enc -out github_deploy_key -dPro Tip: You can add it automatically by running with --add.Make sure to add github_deploy_key.enc to the git repository.Make sure not to add github_deploy_key to the git repository.Commit all changes to your .travis.yml. 注： 如果是 GitHub 项目，建议先通过 travis login 登录，然后再通过 travis encrypt-file github_deploy_key -add 加密，travis Client 会自动更新 .traivs.yaml并且在 travis 中自动添加变量 encrypted_XXXXXXXXXXXX_key 和 encrypted_XXXXXXXXXXXX_iv 删除 github_deploy_key 1rm -f github_deploy_key ​ 修改 .travis.yaml 在 before_install 添加如下内容： 123456789before_install:- openssl aes-256-cbc -K $encrypted_a7d17a00ff1b_key -iv $encrypted_a7d17a00ff1b_iv -in .travis/github_deploy_key.enc -out ~/.ssh/github_deploy_key -d- chmod 600 ~/.ssh/github_deploy_key- eval $(ssh-agent)- ssh-add ~/.ssh/github_deploy_key- cp .travis/ssh_config ~/.ssh/config- git config --global user.name 'gythialy'- git config --global user.email 'gythialy@users.noreply.github.com' 注： 步骤如下：通过openssl 解密文件并输出到 ~/.ssh/github_deploy_key 中；设定 ~/.ssh/github_deploy_key 文件权限并添加到 ssh-agent 中 ssh_config内容，主要是防止首次连接的时候，会弹出提示。如果有其他的地址，参考此设置即可。 123456789101112131415Host github.com User git StrictHostKeyChecking no IdentityFile ~/.ssh/github_deploy_key IdentitiesOnly yesHost gitcafe.com User git StrictHostKeyChecking no IdentityFile ~/.ssh/github_deploy_key IdentitiesOnly yesHost git.coding.net User git StrictHostKeyChecking no IdentityFile ~/.ssh/github_deploy_key IdentitiesOnly yes 至此，就成功在 travis 中添加了SSH密钥且能建立链接。可用于且不限于： 推送 CI 编译后的文件/结果 免费构建私有项目（这个可能会违反TOS，不建议...） etc.... 参考 Connecting to GitHub with SSH Encrypting Files ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>travis</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过 travis 自动部署 Hexo]]></title>
    <url>%2Fauto-deploy-hexo-by-travis%2F</url>
    <content type="text"><![CDATA[准备工作 生成 GitHub 的 Personal access tokens，需要有 repo 相关权限 安装 Git deployer plugin for Hexo 1npm install hexo-deployer-git --save 配置 配置 Hexo 在 Hexo 的_config.yml 中添加 Hexo 编译好后文件的git地址，如果需要同时提交到多个不同地址，可以添加多个。 12345678# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://__GITHUB_TOKEN__@github.com/&#123;user_name&#125;/&#123;git_repo&#125; branch: master name: gythialy email: gythialy@users.noreply.github.com 注：https://__GITHUB_TOKEN__@github.com/{user_name}/{git_repo} 示例为 https://__GITHUB_TOKEN__@github.com/gythialy/gythialy.github.io.git 配置 travis 在 Hexo 根目录添加 .travis.yml，内容如下： 123456789101112131415161718192021222324252627language: node_jsnode_js:- "7"branches: only: - rawbefore_install:- npm install -g hexo-cli- npm install -g gulpinstall:- npm installbefore_script:- git config --global user.name 'gythialy'- git config --global user.email 'gythialy@users.noreply.github.com'- sed -i "s/__GITHUB_TOKEN__/$&#123;__GITHUB_TOKEN__&#125;/" _config.yml# use custom theme config- git clone --branch v5.1.2 --depth=10 https://github.com/iissnan/hexo-theme-next.git themes/next- git checkout -b v5.1.2- cp next_config.yml ./themes/next/_config.ymlscript:- hexo generate &amp;&amp; gulp &amp;&amp; hexo deploy 注： 因为源文件和生成的文件共用了git repo，所以需要指定只编译 源文件分支（raw），master作为编译好的文件存放路径。 配置 travis 环境变量 在 travis 网页中添加变量__GITHUB_TOKEN__值为前面生成的 GitHub Personal access tokens ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>travis</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 通过 JNA 调用 C/C++ 接口]]></title>
    <url>%2Fjna%2F</url>
    <content type="text"><![CDATA[缘起 项目中调用了第三方一个 Matlab 实现的数据清洗和机组状态评价的算法，但是对方不会除 Matlab 外的其他语言，最后只用 Matlab 生成了一个 dll/lib 文件。由于对方提供的接口质量真心不好，而且对方也无力修改。最终方案只好由我方在其基础上用 C++ 重新包装一下。在给我方 Client 调用时，需要把从多数据源查询数据的细节封装掉，最终就形成了Java Client-&gt; Java Interface-&gt;C++ Interface-&gt;Matlab/C++ Interface(第三方) 这样一个诡异的调用链。 因只是 Java 单向调用 C++ 接口，故通过 JNA 实现。主要设计到 JNA 的结构体封装，指针声明及取值，结构体指针定义及取值。 实现 C++ 的封装接口逻辑非常简单，根据业务提供数据清洗和机组评价的两个接口。 由于Matlab 导出的 dll 效率是真心差，尤其时加载的时候，各种抛异常，每次加载dll大约需耗时20~30s。所以不能每次加载，故提供 init/terminator 实现按需加载及停用。 C/C++ 头文件定义 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164#ifndef __CALCULATOR_API_H__#define __CALCULATOR_API_H__#include &lt;cstdint&gt;#ifdef WIN32# define EXPORT_API __declspec(dllexport)#else# define EXPORT_API #endif// Random number to avoid errno conflicts#define CALCULATOR_ENOBASE 112345678/* Calculator exceptions */enum&#123; CALCULATOR_EXCEPTION_ILLEGAL_FUNCTION = 0x01, CALCULATOR_EXCEPTION_ILLEGAL_PARA&#125;;#define EMBXILFUN (CALCULATOR_ENOBASE + CALCULATOR_EXCEPTION_ILLEGAL_FUNCTION)#define EMBXILPARA (CALCULATOR_ENOBASE + CALCULATOR_EXCEPTION_ILLEGAL_PARA)typedef enum&#123; H2 = 0X01, CH4, C2H2, C2H4, TOTAL_HYDROCARBON,//总烃 CO, CO2&#125; OilChromatographyType;/** * 数据清洗结果 */typedef struct sImproveResult&#123; int32_t valid; // 有效数据个数 float validPercent; // 数据有效值占比 float* abnormalData; // 异常数据 int32_t abnormal_size; // 异常数据个数 float* optimizeData; // 优化后的数据 int32_t optimize_size; // 优化数据个数&#125; sImproveResult, *ImproveResult;/** * 变压器输入参数 */typedef struct sTransformer&#123; float h2Value; float totalHydrocarbon; // 总烃 float c2h2Value; float coValue; float co2Value; float dielectricLoss; // 介损 float dcResistance; //直阻 float absorptance; //吸收比 float polarizeFactor; // 极化系数 float electricCapacity; // 电容量 float moisture; // 微水 float breakdownVoltage; // 击穿电压 float oilDielectricLoss; // 油介损 float interfacialTension; //界面张力 float electricResistivity; //电阻率 int16_t runningLife; // 运行年限 float ambientTemperature; // 环境温度 float jointTemperature; //接头温度 float oilTankTemperature; // 油箱温度&#125; sTransformer, *Transformer;/** * 因素状态隶属度结果 */typedef struct sFusionResult&#123; float *h1; // 油色谱 int16_t h1_size; float *h2; // 电气试验 int16_t h2_size; float *h3; // 绝缘油 int16_t h3_size; float *h4; // 其余项 int16_t h4_size; float qz1; // 油色谱权重 float qz2; // 电气试验权重 float qz3; // 绝缘油权重 float qz4; // 其余项权重 float m; // 证据融合参数 float n; // 证据融合参数&#125; sFusionResult, *FusionResult;/** * 最终评价结果 */typedef struct sFactorResult&#123; float* state; int16_t state_size; int8_t* comment; int16_t comment_len;&#125; sFactorResult, *FactorResult;typedef struct&#123; int64_t time; float value;&#125; sImproveInput, *ImproveInput;typedef struct sReviewResult&#123; Transformer indexScore; int16_t indexScore_size; FusionResult indexFusion; FactorResult factorFusion;&#125; sReviewResult, *ReviewResult;#ifdef __cplusplusextern "C"&#123;#endif /** * 数据清洗 * @param original[in] 原始数据起始地址 * @param originalLen[in] 原始数据长度 * @param result [out] 数据清洗结果 * @return 0:成功;非0：失败 */ EXPORT_API int16_t improve_data(const ImproveInput original, const int32_t originalLen, ImproveResult result); /** * 状态评价计算 * @param transformer[in] 主变参数 * @param result[out] 评价结果 * @return 0:成功;非0：失败 */ EXPORT_API int16_t review_transformer(const Transformer transformer, ReviewResult result); /** * 初始化 dll * @return [description] */ EXPORT_API int16_t init(); /** * 根据 err num 获取异常信息描述 * @param errnum[in] errnum * @return errnum 对应的异常信息描述 */ EXPORT_API const int8_t* calculator_strerror(int errnum); /** * 停止计算模块 **/ EXPORT_API void terminator();#ifdef __cplusplus&#125;#endif#endif /*__CALCULATOR_API_H__*/ Java 接口定义 CalculatorApi CalculatorApi 提供与 C++ 头文件中声明一致的函数定义，继承 Library 123456789101112import com.sun.jna.Library;public interface CalculatorApi extends Library &#123; int improve_data(ImproveInputWrapper.ByReference original, int originalLen, ImproveResultWrapper result); int init(); int review_transformer(TransformerWrapper transformer, ReviewResult result); void terminator();&#125; FactorResultWrapper 作为 C++ 中 结构体 FactorResult的封装类，需要继承Structure，原始 state定义为 float *，通过 Pointer 与其对应。必须要实现 getFieldOrder,其中字段的顺序必须和 C++ 中保持一致，且所有相关字段必须要设成 Public 。使用的时候，用的引用传递，所以必须要实现Structure.ByReference接口。具体代码实现如下： 123456789101112131415161718192021222324252627import com.sun.jna.Pointer;import com.sun.jna.Structure;import java.util.List;public class FactorResultWrapper extends Structure &#123; private static final List&lt;String&gt; FIELDS_ORDER = createFieldsOrder("state", "state_size", "comment", "comment_len"); public Pointer state; public int state_size; public String comment; public int comment_len; public static class ByReference extends FactorResultWrapper implements Structure.ByReference &#123; &#125; public static class ByValue extends FactorResultWrapper implements Structure.ByValue &#123; &#125; public FactorResultWrapper() &#123; super(); &#125; @Override protected List&lt;String&gt; getFieldOrder() &#123; return FIELDS_ORDER; &#125;&#125; FusionResultWrapper 作为 C++ 中 结构体 FusionResult的封装类，定义同上。 1234567891011121314151617181920212223242526272829303132333435import com.sun.jna.Pointer;import com.sun.jna.Structure;import java.util.List;public class FusionResultWrapper extends Structure &#123; private static final List&lt;String&gt; FIELDS_ORDER = createFieldsOrder("h1", "h1_size", "h2", "h2_size", "h3", "h3_size", "h4", "h4_size", "qz1", "qz2", "qz3", "qz4", "m", "n"); public Pointer h1; // 油色谱 public int h1_size; public Pointer h2; // 电气试验 public int h2_size; public Pointer h3; // 绝缘油 public int h3_size; public Pointer h4; // 其余项 public int h4_size; public float qz1; // 油色谱权重 public float qz2; // 电气试验权重 public float qz3; // 绝缘油权重 public float qz4; // 其余项权重 public float m; // 证据融合参数 public float n; // 证据融合参数 public static class ByReference extends FusionResultWrapper implements Structure.ByReference &#123; &#125; public static class ByValue extends FusionResultWrapper implements Structure.ByValue &#123; &#125; @Override protected List&lt;String&gt; getFieldOrder() &#123; return FIELDS_ORDER; &#125;&#125; ImproveInputWrapper 作为 C++ 中 结构体 ImproveInput的封装类，就是基本类型映射。 1234567891011121314151617181920import com.sun.jna.Structure;import java.util.List;public class ImproveInputWrapper extends Structure &#123; private static final List&lt;String&gt; FIELDS_ORDER = createFieldsOrder("time", "value"); public long time; public float value; public ImproveInputWrapper() &#123; &#125; public static class ByReference extends ImproveInputWrapper implements Structure.ByReference &#123; &#125; @Override protected List&lt;String&gt; getFieldOrder() &#123; return FIELDS_ORDER; &#125;&#125; ImproveResultWrapper 作为 C++ 中 结构体ImproveResult的封装类 1234567891011121314151617181920212223import com.sun.jna.Pointer;import com.sun.jna.Structure;import java.util.List;public class ImproveResultWrapper extends Structure &#123; private static final List&lt;String&gt; FIELDS_ORDER = createFieldsOrder("valid", "validPercent", "abnormalData", "abnormal_size", "optimizeData", "optimize_size"); public int valid; // 有效数据个数 public float validPercent; // 数据有效值占比 public Pointer abnormalData; // 异常数据 public int abnormal_size; // 异常数据个数 public Pointer optimizeData; // 优化后的数据 public int optimize_size; public static class ByReference extends ImproveResultWrapper implements Structure.ByReference &#123; &#125; @Override protected List&lt;String&gt; getFieldOrder() &#123; return FIELDS_ORDER; &#125;&#125; ReviewResult 作为 C++ 中 结构体ReviewResult的封装类，此处包含多个结构体指针，需要通过 ByReference来声明，且需要分配内存。比如 TransformerWrapper.ByReference indexScore，需要通过 toArray分配内存 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import com.sun.jna.Memory;import com.sun.jna.Native;import com.sun.jna.Structure;import java.util.List;public class ReviewResult extends Structure &#123; private final int STATE_SIZE = 5; private static final List&lt;String&gt; FIELDS_ORDER = createFieldsOrder("indexScore", "indexScore_size", "indexFusion", "factorFusion"); public TransformerWrapper.ByReference indexScore; public int indexScore_size; public FusionResultWrapper.ByReference indexFusion; public FactorResultWrapper.ByReference factorFusion; public ReviewResult() &#123; super(); if (indexScore_size == 0) indexScore_size = STATE_SIZE; indexScore = new TransformerWrapper.ByReference(); TransformerWrapper[] wrappers = (TransformerWrapper[]) indexScore.toArray(indexScore_size); for (TransformerWrapper wrapper : wrappers) &#123; wrapper.h2Value = 0f; wrapper.totalHydrocarbon = 0f; // 总烃 wrapper.c2h2Value = 0f; wrapper.coValue = 0f; wrapper.co2Value = 0f; wrapper.dielectricLoss = 0f; // 介损 wrapper.dcResistance = 0f; //直阻 wrapper.absorptance = 0f; //吸收比 wrapper.polarizeFactor = 0f; // 极化系数 wrapper.electricCapacity = 0f; // 电容量 wrapper.moisture = 0f; // 微水 wrapper.breakdownVoltage = 0f; // 击穿电压 wrapper.oilDielectricLoss = 0f; // 油介损 wrapper.interfacialTension = 0f; //界面张力 wrapper.electricResistivity = 0f; //电阻率 wrapper.runningLife = 0; // 运行年限 wrapper.ambientTemperature = 0f; // 环境温度 wrapper.jointTemperature = 0f; //接头温度 wrapper.oilTankTemperature = 0f; // 油箱温度 &#125; indexFusion = new FusionResultWrapper.ByReference(); indexFusion.h1 = new Memory(STATE_SIZE * Native.getNativeSize(Float.TYPE)); indexFusion.h1_size = STATE_SIZE; indexFusion.h2 = new Memory(STATE_SIZE * Native.getNativeSize(Float.TYPE)); indexFusion.h2_size = STATE_SIZE; indexFusion.h3 = new Memory(STATE_SIZE * Native.getNativeSize(Float.TYPE)); indexFusion.h3_size = STATE_SIZE; indexFusion.h4 = new Memory(STATE_SIZE * Native.getNativeSize(Float.TYPE)); indexFusion.h4_size = STATE_SIZE; factorFusion = new FactorResultWrapper.ByReference(); factorFusion.state = new Memory(STATE_SIZE * Native.getNativeSize(Float.TYPE)); factorFusion.state_size = STATE_SIZE; factorFusion.comment = ""; factorFusion.comment_len = 0; &#125; public static class ByReference extends ReviewResult implements Structure.ByReference &#123; &#125; @Override protected List&lt;String&gt; getFieldOrder() &#123; return FIELDS_ORDER; &#125;&#125; TransformerWrapper 作为 C++ 中 结构体Transformer的封装类 1234567891011121314151617181920212223242526272829303132333435363738394041424344import com.sun.jna.Structure;import java.util.List;public class TransformerWrapper extends Structure &#123; private static final List&lt;String&gt; FIELDS_ORDER = createFieldsOrder("h2Value", "totalHydrocarbon", "c2h2Value", "coValue", "co2Value", "dielectricLoss", "dcResistance", "absorptance", "polarizeFactor", "electricCapacity", "moisture", "breakdownVoltage", "oilDielectricLoss", "interfacialTension", "electricResistivity", "runningLife", "ambientTemperature", "jointTemperature", "oilTankTemperature"); public float h2Value; public float totalHydrocarbon; // 总烃 public float c2h2Value; public float coValue; public float co2Value; public float dielectricLoss; // 介损 public float dcResistance; //直阻 public float absorptance; //吸收比 public float polarizeFactor; // 极化系数 public float electricCapacity; // 电容量 public float moisture; // 微水 public float breakdownVoltage; // 击穿电压 public float oilDielectricLoss; // 油介损 public float interfacialTension; //界面张力 public float electricResistivity; //电阻率 public short runningLife; // 运行年限 public float ambientTemperature; // 环境温度 public float jointTemperature; //接头温度 public float oilTankTemperature; // 油箱温度 public static class ByReference extends TransformerWrapper implements Structure.ByReference &#123; &#125; public static class ByValue extends TransformerWrapper implements Structure.ByValue &#123; &#125; public TransformerWrapper() &#123; super(); &#125; @Override protected List&lt;String&gt; getFieldOrder() &#123; return FIELDS_ORDER; &#125;&#125; CalculatorImpl Java 接口的实现类，首先需要从 Jar 中解压 dll 到指定目录，然后通过此目录加载 dll。依赖关系为 Java 接口通过 JNA 加载calculator.dll ，而calculator.dll依赖 pingjia.dll和另外一个dll。 三个dll必须在同一目录下， JNA 只需要加载 calculator.dll。因为此处只是在 WIN32 平台执行，所以加载时，通过 Native.loadLibrary 加载的时候，在文件名前加了 /，否则 JNA 会在文件前增加平台相关的perfix导致加载失败。 123456789101112131415161718192021222324public class CalculatorImpl implements Calculator &#123; private static final Log LOGGER = Logs.getLog(CalculatorImpl.class); private static CalculatorApi CALCULATOR_API; static &#123; try &#123; String current = System.getProperty("user.dir"); File matlab = new File(current, "matlab"); System.setProperty("java.library.path", matlab.getPath()); System.setProperty("jna.library.path", matlab.getPath()); // 从 Jar 包 resources 中解压 dll 到指定目录 // Files.createDirIfNoExists(matlab); // Files.clearDir(matlab); // 加载 dll 并映射成 Java 接口 CALCULATOR_API = Native.loadLibrary("/calculator.dll", CalculatorApi.class); // 初始化dll (C++ 实现) int ret = CALCULATOR_API.init(); LOGGER.debugf("init calculator (%d)", ret); &#125; catch (Exception e) &#123; LOGGER.error(e.getMessage(), e); &#125; &#125;&#125; 使用 improveData 数据清洗，需要根据Java Wrapper的接口，组织数据，内存都在 Java 端分配，由 Java 端负责回收。Pointer的内存分配，通过 new Memory(size)来分配。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private TwoTuple&lt;String, CalculationResult&gt; improveData(String label, List&lt;TwoTuple&lt;String, Float&gt;&gt; values) throws CalculatorException &#123; ImproveInputWrapper.ByReference inputsRef = new ImproveInputWrapper.ByReference(); final int valueSize = values.size(); ImproveInputWrapper[] inputs = (ImproveInputWrapper[]) inputsRef.toArray(valueSize); LOGGER.debug(label + " inputs: "); for (int i = 0; i &lt; valueSize; i++) &#123; try &#123; TwoTuple&lt;String, Float&gt; entry = values.get(i); Date date = FORMATTER.parse(entry.getKey()); inputs[i].time = date.getTime(); inputs[i].value = entry.getValue(); LOGGER.debugf("%d: %s(%d) -&gt; %f", i, entry.getKey(), inputs[i].time, inputs[i].value); &#125; catch (ParseException e) &#123; LOGGER.error(e.getMessage(), e); &#125; &#125; ImproveResultWrapper.ByReference impResultRef = new ImproveResultWrapper.ByReference(); impResultRef.abnormalData = new Memory(valueSize * Native.getNativeSize(Float.TYPE)); impResultRef.abnormalData.setFloat(0, 0); impResultRef.optimizeData = new Memory(valueSize * Native.getNativeSize(Float.TYPE)); impResultRef.optimizeData.setFloat(0, 0); impResultRef.abnormal_size = 0; impResultRef.validPercent = 0; impResultRef.optimize_size = 0; int flag = CALCULATOR_API.improve_data(inputsRef, inputs.length, impResultRef); LOGGER.debug("improve_data flag: " + flag); CalculationResult.CalculationResultBuilder builder = CalculationResult.CalculationResultBuilder .aCalculationResult().withOriginalData(values); if (flag == 0) &#123; builder.withValidPercent(impResultRef.validPercent).withValidSize(impResultRef.valid); int abnormalSize = impResultRef.abnormal_size; LOGGER.debug("abnormalSize: " + abnormalSize); if (abnormalSize &gt; 0) &#123; float[] abnormalValues = impResultRef.abnormalData.getFloatArray(0, abnormalSize); builder.withAbnormalData(Collections.unmodifiableList(Lang.array2list(abnormalValues, Float.class))); &#125; else &#123; builder.withAbnormalData(Collections.&lt;Float&gt;emptyList()); &#125; int optimizeSize = impResultRef.optimize_size; LOGGER.debug("optimizeSize: " + optimizeSize); if (optimizeSize &gt; 0) &#123; float[] optimizeValues = impResultRef.optimizeData.getFloatArray(0, optimizeSize); builder.withOptimizeData(Collections.unmodifiableList(Lang.array2list(optimizeValues, Float.class))); &#125; else &#123; builder.withOptimizeData(Collections.&lt;Float&gt;emptyList()); &#125; &#125; CalculationResult result = builder.build(); LOGGER.debug(result); return new TwoTuple&lt;&gt;(label, result); &#125; reviewTransformer 机组状态评价，获取 float *的数据时候的，需要通过 getFloatArray 获取数据。 12345678910111213141516171819202122232425262728293031323334private TransformerResult reviewTransformer(Map&lt;String, Float&gt; values) throws CalculatorException &#123; TransformerWrapper.ByReference transformerRef = new TransformerWrapper.ByReference(); setTransformer(transformerRef, values); ReviewResult.ByReference reviewResultRef = new ReviewResult.ByReference(); int flag = CALCULATOR_API.review_transformer(transformerRef, reviewResultRef); LOGGER.debugf("review_transformer flag: %d", flag); TransformerResult result = new TransformerResult(); if (flag == 0) &#123; float[] states = reviewResultRef.factorFusion.state.getFloatArray(0, reviewResultRef.factorFusion.state_size); result.setState(states).setComment(reviewResultRef.factorFusion.comment); float[] h1 = reviewResultRef.indexFusion.h1.getFloatArray(0, reviewResultRef.indexFusion.h1_size); result.setH1(h1); float[] h2 = reviewResultRef.indexFusion.h2.getFloatArray(0, reviewResultRef.indexFusion.h2_size); result.setH2(h2); float[] h3 = reviewResultRef.indexFusion.h3.getFloatArray(0, reviewResultRef.indexFusion.h3_size); result.setH3(h3); float[] h4 = reviewResultRef.indexFusion.h4.getFloatArray(0, reviewResultRef.indexFusion.h4_size); result.setH4(h4); result.setQz1(reviewResultRef.indexFusion.qz1).setQz2(reviewResultRef.indexFusion.qz2) .setQz3(reviewResultRef.indexFusion.qz3).setQz4(reviewResultRef.indexFusion.qz4) .setM(reviewResultRef.indexFusion.m).setN(reviewResultRef.indexFusion.n); TransformerWrapper[] wrappers = (TransformerWrapper[]) reviewResultRef.indexScore.toArray(reviewResultRef.indexScore_size); Transformer[] transformers = transformerWrapperToTransformer(wrappers); result.setTransformers(transformers); LOGGER.debug("transfer review result."); &#125; return result; &#125; 小结 优点 Java 端不需要编写C/C++代码 缺点 需要编写与 C/C++ 对应的结构体映射，碰到复杂的结构体工作量不小 结构体指针/数据通过 toArray获取数据时，效率较低，尤其时数据量比较大的时候 如果时C/C++端分配的内存，Java 端管理不了，如果C/C++不提供显式回收接口，会导致内存泄露 代码不规范，破坏了OO封装性，比如 field 必须要 Public 需要实现 Structure.ByReference接口，这些明显都可以通过注解来解决 ---EOF---]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>C</tag>
        <tag>JNA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GPG 导入导出 Key]]></title>
    <url>%2FHowto-import-export-gpg-key%2F</url>
    <content type="text"><![CDATA[在多台电脑上操作的时候经常会涉及到 GPG 公钥/私钥的导入导出，比方说 GitHub 支持 GPG 加密 Commit，在多台电脑上使用相同的 Key 可以省去很多配置工作。 列出本地的所有 Key 执行 gpg --list-keys 列出本地所有的密钥 输出结果类似 12345 $ gpg --list-keys /home/$USER/.gnupg/pubring.gpg ----------------------------------- pub 4 096R/375A500B 2017-03-22 [有效至：2018-03-22] uid Goren G (Git) &lt;gythialy.koo+git@gmail.com&gt; sub 4096R/ADB9D36C 2017-03-22 [有效至：2018-03-22] 导出 根据 375A500B 导出相应的公钥和私钥 12gpg --output mygpgkey_pub.gpg --armor --export 375A500Bgpg --output mygpgkey_sec.gpg --armor --export-secret-key 375A500B 导入 导入刚导入的文件 12gpg --import ~/mygpgkey_pub.gpggpg --allow-secret-key-import --import ~/mygpgkey_sec.gpg ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>gpg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[babun 配置]]></title>
    <url>%2Fbabun-config%2F</url>
    <content type="text"><![CDATA[介绍 babun 号称是开箱即用的，本质是上就是 cygwin 加上了一些预设的配置。特性如下: Pre-configured Cygwin with a lot of addons Silent command-line installer, no admin rights required pact - advanced package manager (like apt-get or yum) xTerm-256 compatible console HTTP(s) proxying support Plugin-oriented architecture Pre-configured git and shell Integrated oh-my-zsh Auto update feature &quot;Open Babun Here&quot; context menu entry 安装 下载安装包解压缩到任意目录后，运行 install.bat。也可以使用 /t %target_folder% 指定安装目录。 配置 既然是开箱即用，对大多数人来说当然不需要太多配置，一般需要以下两个命令： babun check 用于判断环境是否正确 babun update 用于判断是否有新的更新包 包管理 babun 自带了叫做 pact 的包管理，修改自 apt-cyg, 但比较弱，用法如下： 123456789101112131415161718&#123; ~ &#125; » pact --helppact: Installs and removes Cygwin packages.Usage: "pact install &lt;package names&gt;" to install given packages "pact remove &lt;package names&gt;" to remove given packages "pact update &lt;package names&gt;" to update given packages "pact show" to show installed packages "pact find &lt;patterns&gt;" to find packages matching patterns "pact describe &lt;patterns&gt;" to describe packages matching patterns "pact packageof &lt;commands or files&gt;" to locate parent packages "pact invalidate" to invalidate pact caches (setup.ini, etc.)Options: --mirror, -m &lt;url&gt; : set mirror --invalidate, -i : invalidates pact caches (setup.ini, etc.) --force, -f : force the execution --help --version 和 Windows 共享配置 添加环境变量 HOME，值为 Windows 的用户目录 C:\Users\%USERNAME% 启动 babun，执行 babun install，重启 babun %USERNAME% 不能包含空格。如果用户名已经有空格，参考这里解决。 代理设置 只需要取消 .babunrc 中的注释 (%USERPROFILE%\.babunrc) 12345# Uncomment this lines to set up your proxyexport http_proxy=user:password@server:portexport https_proxy=$http_proxyexport ftp_proxy=$http_proxyexport no_proxy=localhost 镜像 修改 ~/.pact/pact.repo 中的 PACT_REPO 字段 12345678910111213141516#PACT_REPO=http://mirrors.kernel.org/sourceware/cygwin/PACT_REPO=http://mirrors.neusoft.edu.cn/cygwin/# POPULAR HTTP REPOSITORIES# http://mirror.switch.ch/ftp/mirror/cygwin/# POPULAR FTP REPOSITORIES# ftp://mirror.switch.ch/mirror/cygwin/# ftp://ftp.inf.tu-dresden.de/software/windows/cygwin32/# ftp://mirrors.kernel.org/sourceware/cygwin/# ftp://gd.tuwien.ac.at/gnu/cygwin/# ftp://ftp.iij.ad.jp/pub/cygwin/# ftp://mirror.cpsc.ucalgary.ca/cygwin.com/# FULL LIST# http://cygwin.com/mirrors.html 常用开发环境配置 Python babun 自带的 Python2 并没有安装 pip，需要手动安装 123pact install python-setuptools python-mingpact install libxml2-devel libxslt-devel libyaml-develcurl -skS https://bootstrap.pypa.io/get-pip.py | python Ruby 执行 pact install ruby 如果 ruby -v 不能返回版本，执行 update.bat 更新 cygwin 的版本。via Issue #483 FAQ compdef: unknown command or service: git 12$ compinit$ cp .zcompdump .zcompdump-$HOSTNAME-$ZSH_VERSION 删除右键中的 Open Babun here 执行 babun shell-here remove 与 ConEmu 集成 %userprofile%\.babun\cygwin\bin\mintty.exe /bin/env CHERE_INVOKING=1 /bin/zsh.exe X64 官方对于 64 位的解释。懒人也可以直接使用这个 PR 编译的分发包。有兴趣的也可以通过我合并的 x64 分支 自行构建。 总结 总的来说，babun 比 MSYS2 慢，包也不多，稳定性/兼容性貌似好一点。 最终配置效果： ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>babun</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jetty 配置 Log4J]]></title>
    <url>%2Fjetty-log4j-conf%2F</url>
    <content type="text"><![CDATA[缘起 我们一台很老的装置中用了 Jetty v7.1.6，由于种种原因，不能升级新版本。某次由于一个 bug 导致一直写日志，最后把硬盘给写爆了，所以用 Log4J 记录日志，方便控制日志大小等。 注：在 Jetty 最新的版本中，配置 Log4J 并不需要如此。 配置 下载 Log4J log4j-1.2.17.jar slf4j-api-1.7.9.jar slf4j-log4j12-1.7.9.jar 复制 jar 包到 Jetty 目录中 lib/ext 文件夹中 1234-rwxr-xr-x 1 root root 0 Jul 16 2010 .donotdelete-rw-r--r-- 1 root root 489884 Nov 19 13:06 log4j-1.2.17.jar-rw-r--r-- 1 root root 32121 Nov 19 13:09 slf4j-api-1.7.9.jar-rw-r--r-- 1 root root 8867 Nov 19 16:55 slf4j-log4j12-1.7.9.jar 在 Jetty 目录中 resources 文件夹中新建 log4j.properties 1234567891011121314# Basic Log4j Configuration with STDOUT and File logginglog4j.rootLogger=DEBUG, filerlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target=System.outlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d&#123;ABSOLUTE&#125; %5p %c&#123;1&#125;:%L - %m%nlog4j.appender.filer=org.apache.log4j.RollingFileAppenderlog4j.appender.filer.layout=org.apache.log4j.PatternLayoutlog4j.appender.filer.layout.ConversionPattern=%d&#123;ABSOLUTE&#125; %5p %c&#123;1&#125;:%L - %m%nlog4j.appender.filer.File=$&#123;jetty.home&#125;/logs/jetty.loglog4j.appender.filer.MaxFileSize=1MBlog4j.appender.filer.MaxBackupIndex=20 为了测试日志，配置设置的日志打印级别为DEBUG，单个文件大小为 1M，实际使用中根据具体使用场景调整。 修改 start.ini，OPTIONS 中 ext 必须放在 resources 前面 12345678#===========================================================# Start classpath OPTIONS.# These control what classes are on the classpath# for a full listing do# java -jar start.jar --list-options#-----------------------------------------------------------OPTIONS=Server,jsp,jmx,websocket,ext,resources#----------------------------------------------------------- 注：如需手动设置 JVM 内存配置，需要添加 --exec。这样就会有一个 java 进程常在。 创建启动脚本，原理很简单，就是设置 JAVA_HOME 和 JETTY_HOME 两个环境变量，然后调用 Jetty 自身的脚本。如果已经设置全局的环境变量，此步可省略 1234567891011121314151617181920212223#!/bin/shexport JAVA_HOME=/usr/java/jdkexport JETTY_HOME=/home/data/jettycd $JETTY_HOME/binpwdcase "$1" in start) ./jetty.sh start ;; stop) ./jetty.sh stop ;; restart) ./jetty.sh restart ;; *) echo "Usage: $0 $1 &#123;start|stop|restart&#125;" ;;esacexit 0 脚本中 JAVA_HOME 和 JETTY_HOME 是必须的。 效果 12345678910111213141516171819202122-rw-r--r-- 1 root root 27995 Nov 30 14:51 2015_11_27.stderrout.log-rw-r--r-- 1 root root 8060 Nov 30 14:51 EA0104-0.log-rw-r--r-- 1 root root 968686 Nov 30 14:52 jetty.log-rw-r--r-- 1 root root 1050948 Nov 27 15:57 jetty.log.1-rw-r--r-- 1 root root 1048812 Nov 27 15:52 jetty.log.10-rw-r--r-- 1 root root 1050923 Nov 27 15:52 jetty.log.11-rw-r--r-- 1 root root 1051665 Nov 27 15:49 jetty.log.12-rw-r--r-- 1 root root 1050713 Nov 27 15:47 jetty.log.13-rw-r--r-- 1 root root 1051495 Nov 27 15:47 jetty.log.14-rw-r--r-- 1 root root 1052634 Nov 27 15:47 jetty.log.15-rw-r--r-- 1 root root 1052521 Nov 27 15:29 jetty.log.16-rw-r--r-- 1 root root 1049512 Nov 27 15:29 jetty.log.17-rw-r--r-- 1 root root 1051501 Nov 27 15:29 jetty.log.18-rw-r--r-- 1 root root 1049831 Nov 27 15:56 jetty.log.2-rw-r--r-- 1 root root 1051016 Nov 27 15:56 jetty.log.3-rw-r--r-- 1 root root 1049532 Nov 27 15:56 jetty.log.4-rw-r--r-- 1 root root 1052064 Nov 27 15:56 jetty.log.5-rw-r--r-- 1 root root 1049274 Nov 27 15:56 jetty.log.6-rw-r--r-- 1 root root 1050903 Nov 27 15:56 jetty.log.7-rw-r--r-- 1 root root 1051740 Nov 27 15:52 jetty.log.8-rw-r--r-- 1 root root 1052915 Nov 27 15:52 jetty.log.9-rw-r--r-- 1 root root 55 Nov 27 15:52 start.log start.log 是 start.jar 创建的，会根据 etc/jetty-logging.xml 中配置决定是否从定向内容。 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
        <tag>Log4J</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手动下载 XCode 文档和模拟器]]></title>
    <url>%2Fdownload-xcode-documentation-sets-manually%2F</url>
    <content type="text"><![CDATA[缘起 由于众所周知的原因，也就是 Apple 的云真的很烂，App Store 还能通过 DNS 等手段加速更新。对于 XCode 简直就是噩梦，挂不挂都是一个样子，非常慢。不幸中之大幸，虽然 XCode 本身下载很慢，但是可以手动下载好之后，通过 XCode 安装。 文档 手动下载文档可以通过以下几步解决，via stackoverflow。 通过这个地址找到需要下载的文件的路径 12345678910111213141516171819202122232425262728293031323334&lt;!-- START OS X doc set --&gt;&lt;dict&gt; &lt;key&gt;fileSize&lt;/key&gt; &lt;integer&gt;931959772&lt;/integer&gt; &lt;key&gt;identifier&lt;/key&gt; &lt;string&gt;com.apple.adc.documentation.OSX&lt;/string&gt; &lt;key&gt;name&lt;/key&gt; &lt;string&gt;OS X 10.11.4 Documentation&lt;/string&gt; &lt;key&gt;source&lt;/key&gt; &lt;string&gt;https://devimages.apple.com.edgekey.net/docsets/20160321/031-52211-A.dmg&lt;/string&gt; &lt;key&gt;userInfo&lt;/key&gt; &lt;dict&gt; &lt;key&gt;ActivationPredicate&lt;/key&gt; &lt;string&gt;$XCODE_VERSION &amp;gt;= '7.3'&lt;/string&gt; &lt;key&gt;Category&lt;/key&gt; &lt;string&gt;Documentation&lt;/string&gt; &lt;key&gt;IconType&lt;/key&gt; &lt;string&gt;IDEDownloadablesTypeDocSet&lt;/string&gt; &lt;key&gt;InstallPrefix&lt;/key&gt; &lt;string&gt;$(HOME)/Library/Developer/Shared/Documentation/DocSets&lt;/string&gt; &lt;key&gt;InstalledIfAllReceiptsArePresentOrNewer&lt;/key&gt; &lt;dict&gt; &lt;key&gt;com.apple.pkg.10.9.OSXDocset&lt;/key&gt; &lt;string&gt;10.9.0.0.1.1458364023&lt;/string&gt; &lt;/dict&gt; &lt;key&gt;RequiresADCAuthentication&lt;/key&gt; &lt;false/&gt; &lt;key&gt;Summary&lt;/key&gt; &lt;string&gt;My description of content&lt;/string&gt; &lt;/dict&gt; &lt;key&gt;version&lt;/key&gt; &lt;string&gt;1014.5&lt;/string&gt;&lt;/dict&gt;&lt;!-- END OS X doc set --&gt; 下载 source 节点对应的内容，在这个示例中也就是这个，可以通过第三方的下载工具，比如 asia2 下载。 按照 identifier string + - + version string + .dmg 的格式重命名文件，在这个示例中也就是 com.apple.adc.documentation.OSX-1014.5.dmg 把重命名后的文件放到 ~/Library/Caches/com.apple.dt.Xcode/Downloads/ 中，如果没有 Downloads 文件夹就创建一个， 如果 Downloads 中有后缀为 dvtdownloadableindex 的文件，全部删除 删除 ~/Library/Developer/Shared/Documentation/DocSets 中对应的 docset 在 XCode 中 Preferences/Download 中下载对应的文档，XCode 会校验刚才复制过去的文件进行安装 模拟器 打开 XCode，Preferences/Download 中下载模拟器 打开 Console.app，清空日志 在 XCode 中取消下载 在 Console.app 中会看到取消的日志，其他包含完整的下载地址 通过 asia2 等第三方工具下载刚才地址中的文件 把下载好的文件复制到 ~/Library/Caches/com.apple.dt.Xcode/Downloads 中，如果没有 Downloads 文件夹就创建一个， 如果 Downloads 中有后缀为 dvtdownloadableindex 的文件，全部删除 在 XCode 中安装刚才下载的模拟器 如果需要删除不需要的模拟器，可以在 /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs 中直接删除 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>OS X</tag>
        <tag>XCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MSYS2 配置]]></title>
    <url>%2Fmsys2-config%2F</url>
    <content type="text"><![CDATA[介绍 MSYS2 是 MSYS 的一个升级版, 准确的说是集成了 pacman 和 Mingw-w64的 Cygwin 升级版。与 MSYS 最大的区别是移植了 Pacman。 比较 特点 Cygwin MinGW/MSYS MSYS2 是否GNU 否 是 是 软件支持？ 支持绝大多数的 GNU 软件 支持常用软件 支持大多数 GNU 软件 更类似 Linux？ 在 Windows 中模拟 Linux 实现了 Bash 等主要的 Linux 程序 原生 64/32bit 支持 GCC 编译 独立的 Windows/Linux 程序编译(MingGW32 交叉编译/依赖 cygwin1.dll) 独立的 Windows 程序编译 独立的 Windows 程序编译 中文支持 直接支持中文显示和输入法 需要配置才能支持中文显示和输入，删除一个中文字符需要删除 2 次 支持中文显示和输入法，中文帮助系统和中文提示（部分软件） 运行速度 慢 快 快 安装 安装 MSYS2 从官网下载 MSYS2 安装文件, 一路 Next 即可。 安装开发环境 pacman -S --needed base-devel msys2-devel mingw-w64-x86_64-toolchain 配置 环境变量 123MSYS_HOME=D:\msys64MINGW_HOME=D:\msys64\mingw64LIBRARY_PATH=D:\msys64\mingw64\lib 镜像配置 如果网络环境不好的话，可以增加国内的镜像，速度改进非常明显。 修改 /etc/pacman.d/ 文件夹中修改 mirrorlist 开头的三个文件： mirrorlist.mingw32 12345678910#### 32-bit Mingw-w64 repository mirrorlist##Server=http://mirrors3.ustc.edu.cn/msys2/REPOS/MINGW/i686## Primary## msys2.orgServer = http://repo.msys2.org/mingw/i686Server = http://downloads.sourceforge.net/project/msys2/REPOS/MINGW/i686Server = http://www2.futureware.at/~nickoe/msys2-mirror/i686/ mirrorlist.mingw64 12345678910#### 64-bit Mingw-w64 repository mirrorlist##Server=http://mirrors3.ustc.edu.cn/msys2/REPOS/MINGW/x86_64## Primary## msys2.orgServer = http://repo.msys2.org/mingw/x86_64Server = http://downloads.sourceforge.net/project/msys2/REPOS/MINGW/x86_64Server = http://www2.futureware.at/~nickoe/msys2-mirror/x86_64/ mirrorlist.msys 1234567891011#### MSYS2 repository mirrorlist##Server=http://mirrors3.ustc.edu.cn/msys2/REPOS/MSYS2/$arch## Primary## msys2.orgServer = http://repo.msys2.org/msys/$archServer = http://downloads.sourceforge.net/project/msys2/REPOS/MSYS2/$archServer = http://www2.futureware.at/~nickoe/msys2-mirror/msys/$arch/ 代理 如果需要通过代理才能上网的话，可以在 /etc/profile.d/ 增加 proxy.sh，内容如下: 123456export http_proxy=%PROXY_SERVER%:%PROXY_PORT%export https_proxy=%PROXY_SERVER%:%PROXY_PORT%export ftp_proxy=%PROXY_SERVER%:%PROXY_PORT%export HTTP_PROXY=%PROXY_SERVER%:%PROXY_PORT%export HTTPS_PROXY=%PROXY_SERVER%:%PROXY_PORT%export FTP_PROXY=%PROXY_SERVER%:%PROXY_PORT% 用户目录 修改 /etc/fstab，映射用户目录，与宿主共享配置，这样类似 gitconfig 这样的配置只需要配置一份。 123456# For a description of the file format, see the Users Guide# http://cygwin.com/cygwin-ug-net/using.html#mount-table# DO NOT REMOVE NEXT LINE. It remove cygdrive prefix from pathnone / cygdrive binary,posix=0,noacl,user 0 0C:/Users /home ntfs binary,noacl,auto 1 1 公用 HOME 目录 环境变量中添加 MSYS2_PATH_TYPE 值为 inherit 包管理 刷新软件包 pacman -Sy 安装新包 pacman -S &lt;package_names|package_groups&gt; 删除 pacman -R &lt;package_names|package_groups&gt; 搜索 pacman -Ss &lt;name_pattern&gt; 更多请参考 Arch Linux wiki. 安装zsh和oh my zsh 安装zsh 12pacman -Syupacman -S zsh 安装 oh my zsh 1sh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)" zsh 的配置文件是 ~/.zshrc，可以通过编辑这个文件来指定主题，插件。 重新安装 如果在使用过程中， MSYS2 出现不可恢复的问题的时候，可以通过保存安装的 packages 到文件中，再通过此文件重新安装。 保存现有安装包列表到 C 盘中的 packages.txt pacman -Qqe | xargs echo &gt; /c/packages.txt ; exit 根据保存的 packages.txt 安装 123pacman -Sypacman --needed -S bash pacman pacman-mirrors msys2-runtimepacman -S --needed --force $(cat /c/packages.txt) 坑 如果你使用 MacType 的话，请一定在 default.ini (MacType的配置文件) 添加 gpg/pacman 的例外。 123[UnloadDll]gpg.exepacman.exe via #393 GPGME error: Invalid crypto engine 如果你使用 VirtualBox 4.3.14+ 的话，也需要把相关进程排除。via VirtualBox 4.3.12以后的E_FAIL (0x80004005)问题 ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>msys2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修正 SourceTree 无法识别 msys2 中 Git]]></title>
    <url>%2Ffix-sourcetree-can-not-find-msys2-git%2F</url>
    <content type="text"><![CDATA[问题 SourceTree 真是一个让人又爱又恨的产品，小问题不断，但是在免费的 Git 的 GUI 里面还算优秀的。因为 TortoiseGit 对 msys2 支持不好，我又回到 SourceTree 阵营了, SourceTree 为主， CLI 辅助。 因为 SourceTree 不能识别 msys2 的 Git，虽然其自带一个内嵌的 Git，这样就导致了我需要配置两份全局的 gitconfig。 解决方案 其实原因很简单，因为 SourceTree 要求 Git 所在目录必须同时有 bin 和 cmd 文件夹。听起来很2是吧？知道了原因要解决起来就很简单。 我的 msys2 安装在 d:\msys64，在 SourceTree 中选择 系统安装的Git (工具/选项/Git) 在 AppData 中的 user.config 配置中 GitSystemPath 节点会自动识别出 msys2 的路径 123&lt;setting name="GitSystemPath" serializeAs="String"&gt; &lt;value&gt;D:\msys64\usr&lt;/value&gt;&lt;/setting&gt; 通过 mklink 建立一个链接 在 D:\msys64\usr 建立链接 mklink /D cmd bin ---EOF---]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>SourceTree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eDNA C API 介绍]]></title>
    <url>%2Fedna-api-demo-by-c%2F</url>
    <content type="text"><![CDATA[介绍 eDNA是一个领导性的实时/历史数据系统。eDNA采集、存储和展示大量的工程和运行信息。eDNA将深入在整个企业范围内的数据采集上来，以极高的无损压缩方式存储起来，使得以时间序列频繁变化的数据能以原有的数据精度和时间精度在线保存多达几十年。eDNA使基于运行状况的及时和准确的决策成为可能，极大地降低运行成本。eDNA具有完全分布的体系结构，让正确的人在正确的时间做出正确的决定。eDNA是一套实时的运行管理解决方案，它提供了对你的生产运行中无限制的观察和分析，使得你能够根据丰富的信息迅速地做出决策，你的一线生产能力将会大大提高。via 印步 API eDNA 分为两种： 常规API：支持 C/C++/Visual Basic 等。这种方式需要自己组装报文，虽然有相关 API 函数支持，但是实际应用起来还是比较麻烦 EzDNA：封装了常用的操作，只需要引入一个头文件 (EzDnaApi.h) 即可。 注：两种方式都需要安装 eDNA 的 Client 程序。 示例代码 涉及到的 API 函数： DNAGoodPointFormat 检查测点名称是否符合命名规范 DoesIdExist 检查测点是否存在 DNAGetRTFull 查询指定测点的实时数据 DNAGetHSFull 同上 注： DNAGetHSFull 查询到的时间精度是毫秒，如果对时间有要求，建议使用此函数。但是在实际使用过程中，发现此函数有时候会查询不到数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960int16_t getsnapshot()&#123; edna_tag_t *tag; int32_t index; int32_t *buff_size; int16_t counter; int32_t ret; int8_t log_tag[MAX_BUFF_SIZE]; int8_t szValue[EDNA_LEN]; int32_t ptTime; int8_t szmS[EDNA_LEN]; uint16_t pusStatus; int8_t szStatus[EDNA_LEN]; int8_t szDesc[EDNA_DESC_LEN]; int8_t szUnits[EDNA_LEN]; strncpy(log_tag, "getsnapshot", MAX_BUFF_SIZE); // init parameters // .... for (index = 0; index &lt; ptbl_data-&gt;point_size; index++, tag++) &#123; // other stuff // ... if (tag-&gt;flag == E_EMPTY_TAG) continue; // tests the string, validating it as a fully qualified eDNA point name if (DNAGoodPointFormat(tag-&gt;name) == 0) &#123; tag-&gt;flag = INVALID; continue; &#125; // check point name is exist if (!DoesIdExist(tag-&gt;name)) &#123; tag-&gt;flag = NOT_EXIST; continue; &#125; // retrieves the value, time and status in their raw formats ret = DNAGetRTFull(tag-&gt;name, &amp;tag-&gt;value, szValue, EDNA_LEN, &amp;ptTime, tag-&gt;ts, EDNA_LEN, &amp;pusStatus, szStatus, EDNA_LEN, szDesc, EDNA_DESC_LEN, szUnits, EDNA_LEN);#if 0 ret = DNAGetHSFull(tag-&gt;name, &amp;tag-&gt;value, szValue, EDNA_LEN, &amp;ptTime, tag-&gt;ts, EDNA_LEN, &amp;tag-&gt;ms, szmS, EDNA_LEN, &amp;pusStatus, szStatus, EDNA_LEN, szDesc, EDNA_DESC_LEN, szUnits, EDNA_LEN);#endif tag-&gt;flag = (ret == 0) ? NORMAL : OFFLINE; &#125; return TRUE;&#125; ---EOF---]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>C</tag>
        <tag>eDNA</tag>
        <tag>rtdb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSI PI C API 介绍]]></title>
    <url>%2Fosi-pi-api-demo-by-c%2F</url>
    <content type="text"><![CDATA[介绍 PI（Plant Information System）是由美国 OSIsoft 公司开发的一套基于 Client/Server 结构的商品化软件应用平台，是过程工业全厂信息集成的必然选择。作为工厂底层控制网络与上层管理信息系统网络连接的桥梁，PI 在工厂信息集成中扮演着特殊和重要的角色。更详细的介绍，可参考百度百科或者官方网站 登录数据库 要访问数据库，有两种方法，一种是通过用户名和密码登录，另一种是通过 PI Trust。官方是不建议使用密码登录的，所以在开发应用的时候，尽可能使用 PI Trust，但是国内的情况比较混乱，很多生产环境都还是使用第一次方式。 下面分别介绍两种登录方法的使用 用户名/密码登录 这种方式比较简单，Server 端几乎不需要任何配置，只要简单添加一个用户即可。 涉及到的 API 函数： piut_setservernode 设置 PI Server 节点，一般就是 Server 的 IP 地址 piut_isconnected 是否已经和 Server 连接 piut_login 传入用户名/密码，根据返回值判断是否连接成功，如果需要写数据的话，需要注意写权限 在 PI 3.x 中，默认是不启用用户名/密码登录的，需要注意 PI Trust 登录 这种方式，是官方推荐做法，需要在 Server 段添加相应的 PI Trust 设置，可以设置 IP 地址/Client 名称/进程名字等，配置非常灵活。 涉及到的 API 函数： piut_setservernode 同上 piut_isconnected 同上 piut_setprocname 设置 Client 的进程名，需要和 Server 段设置一致 piut_connect 连接 Server 示例代码，功能就是根据配置参数自动判断连接方式，因为我们生产环境是个很老的现场，所以优先使用用户名/密码登录 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566error_t connect_pi(server_info_t *server)&#123; int32_t result; int32_t valid; int8_t version[SERVER_FIELD_SIZE]; int8_t log_tag[MAX_BUFF_SIZE]; int8_t pro_name[SERVER_FIELD_SIZE]; valid = PIREAD; strncpy(log_tag, "connect pi", MAX_BUFF_SIZE); if (piut_isconnected() == 0) &#123; // retrieves the version number of the PI-API. if (piut_getapiversion(version, sizeof(version)) == 0) &#123; ftrace_log(log_tag, "PI-API version %s", version); &#125; if (server-&gt;misc3 == NULL || strlen(server-&gt;misc3) == 0) &#123; strncpy(pro_name, "pi_snap", SERVER_FIELD_SIZE); &#125; else &#123; strncpy(pro_name, server-&gt;misc3, SERVER_FIELD_SIZE); &#125; // sets the active PI Server node where the data for the subsequent // PI-API calls will be resolved result = piut_setservernode(server-&gt;server_ip); if (result) &#123; ftrace_log(log_tag, "piut_setservernode: can not connect to %s", server-&gt;server_ip); return E_CONNECT_FAILED; &#125; if (server-&gt;usr_name != NULL &amp;&amp; strlen(server-&gt;usr_name) &gt; 0) &#123; // establishes a user's access to PI System data based on a login to a configured user database result = piut_login(server-&gt;usr_name, server-&gt;usr_pwd, &amp;valid); if (result == 0) &#123; ftrace_log(log_tag, "piut_login: connect to %s successful, valid=%d", server-&gt;server_ip, valid); return E_SUCCESS; &#125; ferror_log(log_tag, "piut_login: connect to %s failed, ret=%d", server-&gt;server_ip, result); &#125; //sets the global process name to the passed string piut_setprocname(pro_name); result = piut_connect(server-&gt;server_ip); if (result) &#123; ferror_log(log_tag, "piut_connect: connect to %s failed, ret=%d", server-&gt;server_ip, result); return E_CONNECT_FAILED; &#125; &#125; return E_SUCCESS;&#125; 初始化测点信息 连接上 Server 之后，需要根据测点信息，转换成数据库中对应的id，方便后面的操作 涉及到的 API 函数： pipt_findpoint 转换测点名称为测点号 (必须) pipt_pointtypex 根据测点号查询对应的测点类型 pipt_displaydigits 根据测点号查询显示位数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879static int16_t init_pi_tag(pi_tag_t *tag)&#123; int32_t result; int8_t log_tag[MAX_BUFF_SIZE]; strncpy(log_tag, "init_pi_tag", MAX_BUFF_SIZE); // gets the point number for the given tagname result = pipt_findpoint(tag-&gt;name, &amp;tag-&gt;point_id); if (result) &#123; ftrace_log(log_tag, "fetch point[%s] id failed.", tag-&gt;name); tag-&gt;stat = NOT_EXIST; return FALSE; &#125; // gets the data type code for the passed point number result = pipt_pointtypex(tag-&gt;point_id, &amp;tag-&gt;pt_typex); if (result) &#123; ftrace_log(log_tag, "fetch point[%s] typex failed.", tag-&gt;name); tag-&gt;stat = INVALID; return FALSE; &#125; // gets the display digits attribute for the passed point number result = pipt_displaydigits(tag-&gt;point_id, &amp;tag-&gt;display_prec); if (result) &#123; ftrace_log(log_tag, "fetch point[%s] display digits failed.", tag-&gt;name); tag-&gt;display_prec = -5; &#125; tag-&gt;stat = NORMAL; tag-&gt;rval = (float64_t) 0.0; tag-&gt;istat = 0; tag-&gt;ival = 0; tag-&gt;flag = 0; ftrace_log(log_tag, "name:%s, id:%d, dis_prec: %d,type: %d", tag-&gt;name, tag-&gt;point_id, tag-&gt;display_prec, (int32_t)tag-&gt;pt_typex); switch (tag-&gt;pt_typex) &#123; case PI_Type_PIstring: case PI_Type_blob: case PI_Type_PItimestamp: if (tag-&gt;bsize == 0) &#123; /* Skip allocation if a subsequent run. */ if ((tag-&gt;bval = (void *)malloc(BVALUE_BUFF)) == NULL) &#123; error_log(log_tag, "malloc bval failed."); destory(); return E_MALLOC_FAILED; &#125; &#125; tag-&gt;bsize = (tag-&gt;bsize &gt; BVALUE_BUFF - 1) ? tag-&gt;bsize : BVALUE_BUFF - 1; memset(tag-&gt;bval, 0, (size_t)(tag-&gt;bsize + 1)); break; case PI_Type_int16: case PI_Type_int32: tag-&gt;bsize = 0; break; case PI_Type_digital: tag-&gt;bsize = 0; break; default:/* floats, PI2 */ tag-&gt;bsize = 0; break; &#125; /* End switch */ return TRUE;&#125; 查询实时数据 从快照中查询数据库，可以通过 pisn_getsnapshot 或者 pisn_getsnapshotx 查询，具体可查考 API 文档。 注： pisn_getsnapshot 获取的时间只到秒级，如果对时间精度要求比较高，需要使用 pisn_getsnapshotx。 1234567891011121314151617181920212223242526272829303132int16_t getsnapshot()&#123; // init parameters etc. // ... for (index = 0; index &lt; ptbl_data-&gt;point_size; index++, tag++) &#123; // check server connection etc // ... tag-&gt;rval = 0; tag-&gt;istat = 0; result = pisn_getsnapshot(tag-&gt;point_id, &amp;tag-&gt;rval, &amp;tag-&gt;istat, &amp;tag-&gt;time); if (result == 0) &#123; ftrace_log(log_tag, "%s[0x%p] pisn_getsnapshot, rval=%f,ival=%d,time=%d", tag-&gt;name, tag, tag-&gt;rval, tag-&gt;istat, tag-&gt;time); &#125; else if (result == -1) &#123; tag-&gt;stat = NOT_EXIST; ftrace_log(log_tag, "%s pisn_getsnapshot not exist, result=%d.", tag-&gt;name, result); &#125; else &#123; tag-&gt;stat = INVALID; ftrace_log(log_tag, "%s pisn_getsnapshot failed, result=%d.", tag-&gt;name, result); &#125; &#125; return TRUE;&#125; ---EOF---]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>C</tag>
        <tag>rtdb</tag>
        <tag>PI</tag>
      </tags>
  </entry>
</search>
